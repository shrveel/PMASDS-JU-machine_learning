{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6767ce7",
   "metadata": {},
   "source": [
    "# Boston House Price Prediction using regression model\n",
    "## WMASDS22: Machine Learning for Data Science\n",
    "- Multiple Linear Regression \n",
    "- Polynomial Regression\n",
    "- Regularization \n",
    "  - Lasso (L1)\n",
    "  - Ridge (L2)\n",
    "- Hyperparameter Tuning\n",
    "- Cross Validation\n",
    "  - Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541c962e",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0f9046f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd                      \n",
    "import matplotlib.pyplot as plt          # plotting library\n",
    "import seaborn as sns                    # plotting library\n",
    "\n",
    "from sklearn.datasets import load_boston # to load the dataset\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso # regression model\n",
    "from sklearn.preprocessing import PolynomialFeatures, scale     # preprocessing steps\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score # cross validation\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e6dd7a",
   "metadata": {},
   "source": [
    "### Load the boston data from scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e35291b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n",
      "dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename'])\n"
     ]
    }
   ],
   "source": [
    "boston = load_boston()\n",
    "print(type(boston))\n",
    "print(boston.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87232095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(boston.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799de0d4",
   "metadata": {},
   "source": [
    "### Create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d499cb06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.9</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.9</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "\n",
       "   PTRATIO      B  LSTAT  Price  \n",
       "0     15.3  396.9   4.98   24.0  \n",
       "1     17.8  396.9   9.14   21.6  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=boston.data, columns=boston.feature_names)\n",
    "df['Price'] = boston.target\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0437b8",
   "metadata": {},
   "source": [
    "### Perform EDA\n",
    "- perform tabular and graphical EDA for better understanding your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a28ac6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   CRIM     506 non-null    float64\n",
      " 1   ZN       506 non-null    float64\n",
      " 2   INDUS    506 non-null    float64\n",
      " 3   CHAS     506 non-null    float64\n",
      " 4   NOX      506 non-null    float64\n",
      " 5   RM       506 non-null    float64\n",
      " 6   AGE      506 non-null    float64\n",
      " 7   DIS      506 non-null    float64\n",
      " 8   RAD      506 non-null    float64\n",
      " 9   TAX      506 non-null    float64\n",
      " 10  PTRATIO  506 non-null    float64\n",
      " 11  B        506 non-null    float64\n",
      " 12  LSTAT    506 non-null    float64\n",
      " 13  Price    506 non-null    float64\n",
      "dtypes: float64(14)\n",
      "memory usage: 55.5 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f18d606",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f4e517",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "prepare your dataset for modeling\n",
    "  - do necessary changes like feature selection, feature scaling etc (when needed)\n",
    "  - create/transform features (if necessary)\n",
    "  - drop or impute missing values (if any)\n",
    "  - Encoding catergorical features (if any)\n",
    "  - identifying or eliminating outliers (if any)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35222ace",
   "metadata": {},
   "source": [
    "###  Is there any missing value in the dataset? which variable contains missing value? How to fill/impute missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58da6479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       0\n",
       "ZN         0\n",
       "INDUS      0\n",
       "CHAS       0\n",
       "NOX        0\n",
       "RM         0\n",
       "AGE        0\n",
       "DIS        0\n",
       "RAD        0\n",
       "TAX        0\n",
       "PTRATIO    0\n",
       "B          0\n",
       "LSTAT      0\n",
       "Price      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e49464",
   "metadata": {},
   "source": [
    "**There is no missing values!** In practice, this is very rare, we expect to have some missing entries!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe5a940",
   "metadata": {},
   "source": [
    "### Partitioning features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40098c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((506, 13), (506,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('Price', axis = 1)\n",
    "y = df['Price']\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d381e668",
   "metadata": {},
   "source": [
    "#### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0878caa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404, 13), (102, 13), (404,), (102,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, stratify=X['CHAS']>0,test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff56dd6",
   "metadata": {},
   "source": [
    "### Perform Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1dbde6bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61b24de",
   "metadata": {},
   "source": [
    "- Question: **Is the model underfitted?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e412030",
   "metadata": {},
   "source": [
    "#### Model's Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e04c6830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on training dataset usnig linear regression model: 0.751\n",
      "score on test dataset using linear regression model: 0.669\n"
     ]
    }
   ],
   "source": [
    "# Training score\n",
    "lr_score_train  = lr.score(X_train, y_train)\n",
    "lr_score_test = lr.score(X_test, y_test)\n",
    "\n",
    "print('score on training dataset usnig linear regression model:', round(lr_score_train,3))\n",
    "print('score on test dataset using linear regression model:', round(lr_score_test,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19f9698",
   "metadata": {},
   "source": [
    "**The model is probably underfitted!**\n",
    "<br>\n",
    "- Question: How to improve model performance? (e.g., polynomial regression, regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3dd5408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed R2 0.751\n"
     ]
    }
   ],
   "source": [
    "# Calculate score explicitly without using module/function\n",
    "import numpy as np\n",
    "mean_y = np.mean(y_train)\n",
    "squared_errors_mean = np.sum((y_train - mean_y)**2)\n",
    "squared_errors_model = np.sum((y_train -lr.predict(X_train))**2)\n",
    "R2 = 1 - (squared_errors_model / squared_errors_mean)\n",
    "print ('Computed R2', round(R2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1833a45e",
   "metadata": {},
   "source": [
    "### Show the coefficients\n",
    "- **Find the coefficients of multiple linear regression model for predicting house price.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a0a2190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30.24675099392408,\n",
       " array([-1.13055924e-01,  3.01104641e-02,  4.03807204e-02,  2.78443820e+00,\n",
       "        -1.72026334e+01,  4.43883520e+00, -6.29636221e-03, -1.44786537e+00,\n",
       "         2.62429736e-01, -1.06467863e-02, -9.15456240e-01,  1.23513347e-02,\n",
       "        -5.08571424e-01]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.intercept_,  lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82fc5c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coef = pd.DataFrame(data = boston.feature_names, columns = ['Features'])\n",
    "# coef['Coefficients']=lr.coef_\n",
    "# coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1b52ee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIM</td>\n",
       "      <td>-0.113056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZN</td>\n",
       "      <td>0.030110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDUS</td>\n",
       "      <td>0.040381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHAS</td>\n",
       "      <td>2.784438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOX</td>\n",
       "      <td>-17.202633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RM</td>\n",
       "      <td>4.438835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AGE</td>\n",
       "      <td>-0.006296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DIS</td>\n",
       "      <td>-1.447865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RAD</td>\n",
       "      <td>0.262430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TAX</td>\n",
       "      <td>-0.010647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PTRATIO</td>\n",
       "      <td>-0.915456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B</td>\n",
       "      <td>0.012351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LSTAT</td>\n",
       "      <td>-0.508571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  Coefficients\n",
       "0      CRIM     -0.113056\n",
       "1        ZN      0.030110\n",
       "2     INDUS      0.040381\n",
       "3      CHAS      2.784438\n",
       "4       NOX    -17.202633\n",
       "5        RM      4.438835\n",
       "6       AGE     -0.006296\n",
       "7       DIS     -1.447865\n",
       "8       RAD      0.262430\n",
       "9       TAX     -0.010647\n",
       "10  PTRATIO     -0.915456\n",
       "11        B      0.012351\n",
       "12    LSTAT     -0.508571"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef = pd.DataFrame(data=lr.coef_ , columns = ['Coefficients'], index = boston.feature_names)\n",
    "coef.reset_index(inplace=True)\n",
    "coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85460459",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f72ca123",
   "metadata": {},
   "source": [
    "### Encoding Qualitative Variable (if any)\n",
    "- Which method will you prefer for encoding categorical varialbes? Label Econding or One-hot Encoding? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca5c3a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "LE = LabelEncoder()\n",
    "OHE = OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccb3112a",
   "metadata": {},
   "outputs": [],
   "source": [
    "qualitative = ['red', 'red', 'green', 'blue', 'red', 'blue', 'blue', 'green'] # catergorical/qualitative data\n",
    "\n",
    "labels = LE.fit_transform(qualitative).reshape(-1, 1) # Label encoding\n",
    "# print(LE.classes_)\n",
    "# print(labels)\n",
    "\n",
    "# print(OHE.fit_transform(labels)) # One Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413c5f67",
   "metadata": {},
   "source": [
    "#### Create dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f58bfa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat_en=pd.DataFrame(data=OHE.fit_transform(labels), columns = LE.classes_)\n",
    "# df_cat_en"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d86a1f",
   "metadata": {},
   "source": [
    "#### One Hot Encoding using get_dummies from pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e55ceec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = pd.DataFrame(qualitative, columns=['colors'])\n",
    "df_cat_gd = pd.get_dummies(cat)\n",
    "# df_cat_gd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2327de",
   "metadata": {},
   "source": [
    "## Polynomial Regression\n",
    "- Is the model overfitted/underfitted? How to improve model performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fffae843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "change the dimension of feature matrix:  (404, 13) to (404, 105) \n",
      "\n",
      "Train R2 score for polynomial regression: 0.9388251256169509\n",
      "Test R2 score for polynomial regression: 0.8065890290078337\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "pf = PolynomialFeatures(degree=2)\n",
    "\n",
    "X_train_poly = pf.fit_transform(X_train) # Transform features to polynomial of degree 2\n",
    "print('\\nchange the dimension of feature matrix: ',X_train.shape, 'to', X_train_poly.shape,'\\n')\n",
    "\n",
    "PR = LinearRegression()\n",
    "PR.fit(X_train_poly, y_train) # Fit the polynomial regression model\n",
    "\n",
    "r2 = PR.score(X_train_poly, y_train) # scores on train data\n",
    "print('Train R2 score for polynomial regression:',r2)\n",
    "\n",
    "X_test_poly = pf.transform(X_test) # transform test features\n",
    "r2_test = PR.score(X_test_poly, y_test)# scores on test data\n",
    "print('Test R2 score for polynomial regression:',r2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5970982a",
   "metadata": {},
   "source": [
    "**The model is overfitted! Since the training score is much higher than the test score.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e16058",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb50f2de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77501982, 0.62424945, 0.7594282 , 0.78766681, 0.67581438])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#perform cross validation in linear regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "lr = LinearRegression()\n",
    "scores_lr = cross_val_score(lr, X_train, y_train, scoring='r2', cv=5)\n",
    "scores_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc857319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09859507, 0.77732348, 0.71374143, 0.84206701, 0.76337186])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#perform cross validation in polynomial regression\n",
    "PR = LinearRegression()\n",
    "PR.fit(X_train_poly, y_train)\n",
    "scores_poly = cross_val_score(PR, X_train_poly, y_train, scoring='r2', cv=5)\n",
    "scores_poly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65773a54",
   "metadata": {},
   "source": [
    "**Clearly! an overfitted model**\n",
    "- Explain-why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9e66cb",
   "metadata": {},
   "source": [
    "## Regularization\n",
    "- Is regularization techniques improve the performance of your model? which technique do you prefer?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f424f5",
   "metadata": {},
   "source": [
    "#### L1 : LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "785bf9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score: 0.24922195454970486\n",
      "train score: 0.23116549488143734\n"
     ]
    }
   ],
   "source": [
    "# lasso with linear features\n",
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso(alpha = 50, max_iter = 1000, tol = 0.1)\n",
    "lasso.fit(X_train, y_train)\n",
    "print('test score:',lasso.score(X_test, y_test))\n",
    "print('train score:',lasso.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a544fb1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.24026129, 0.18547564, 0.25884267, 0.27323669, 0.11079364])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross validation with LASSO for linear features\n",
    "from sklearn.model_selection import cross_val_score\n",
    "lasso = Lasso(alpha = 50, max_iter = 1000, tol = 0.1)\n",
    "\n",
    "scores_lasso = cross_val_score(lasso, X_train, y_train, scoring='r2', cv=5)\n",
    "scores_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23f3fe0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score (L1): 0.8246549483584114\n",
      "test score (L1): 0.7892995079242417\n"
     ]
    }
   ],
   "source": [
    "# LASSO with polynomial features\n",
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso(alpha = 50, max_iter = 1000, tol = 0.1)\n",
    "lasso.fit(X_train_poly, y_train)\n",
    "\n",
    "print('train score (L1):',lasso.score(X_train_poly, y_train))\n",
    "print('test score (L1):',lasso.score(X_test_poly, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8ebdca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78898182, 0.71459725, 0.85051456, 0.84146452, 0.74992957])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#perform cross validation in LASSO with polynomial features\n",
    "lasso = Lasso(alpha = 50, max_iter = 1000, tol = 0.1)\n",
    "scores_poly_lasso = cross_val_score(lasso, X_train_poly, y_train, scoring='r2', cv=5)\n",
    "scores_poly_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b751e123",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac84a130",
   "metadata": {},
   "source": [
    "#### L2: Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10d1357b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score (L2): 0.7438801903180616\n",
      "test score (L2): 0.6628922072683874\n",
      "[-0.10696184  0.03448822 -0.01897629  2.12418278 -3.41613155  4.36224263\n",
      " -0.01574942 -1.25328057  0.24359372 -0.01233222 -0.76793697  0.01283782\n",
      " -0.54566807]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "rr = Ridge(alpha = 5, max_iter = 100, tol = 0.1)\n",
    "rr.fit(X_train,y_train)\n",
    "print('train score (L2):',rr.score(X_train, y_train))\n",
    "print('test score (L2):',rr.score(X_test, y_test))\n",
    "print(rr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32033f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score (L2) with polynomial features: 0.9319236032704733\n",
      "test score (L2) with polynomial features: 0.7983877074162816\n",
      "\n",
      "\n",
      "[ 0.00000000e+00 -3.04952558e-01  1.31130230e-03 -7.07740396e-01\n",
      "  1.56488180e-01  5.47465170e-02  8.51568720e-01  5.03696813e-01\n",
      " -1.75969603e-01  8.84015490e-01 -1.36230942e-02 -6.32830213e-01\n",
      "  1.89710575e-01 -8.33150552e-01  3.04290717e-04 -2.17376481e-02\n",
      "  2.78700927e-01  2.73301813e+00 -1.34432356e+00  1.87960504e-01\n",
      " -1.99254413e-03 -4.28328878e-02  2.18837564e-01 -2.11330955e-02\n",
      "  1.74200103e-01 -4.24544502e-04  2.75006388e-02  5.64144798e-04\n",
      "  5.52149261e-04 -1.34414821e-02  7.62669591e-02 -1.08583496e-02\n",
      "  4.78765048e-04 -1.81430999e-02 -1.34894810e-02  4.01987227e-04\n",
      "  6.95009678e-03 -1.10011752e-04 -9.46612152e-03  2.95586930e-02\n",
      " -1.94882630e-01  4.44703759e-01  7.47776167e-02  3.38188516e-03\n",
      "  2.75645807e-02  9.91914091e-03  9.07463463e-04 -7.29823173e-02\n",
      "  5.57937879e-04 -2.49878994e-02  1.56488180e-01 -2.56760597e-01\n",
      " -2.70849817e+00  4.69188107e-02  4.86352002e-03 -3.44829946e-01\n",
      " -1.51866312e-02  9.09501498e-01  2.72812660e-02 -4.28836979e-01\n",
      "  2.71169525e-02  3.62566614e-01 -1.57033835e-01  9.76353100e-01\n",
      " -5.10946850e-01 -2.24554883e-02  1.80516525e-01 -1.12472530e-02\n",
      "  8.70475378e-01  1.43112564e+00 -4.51624762e-02  6.60920744e-02\n",
      " -3.48373530e-01 -3.96850225e-03 -3.26483208e-01 -5.51112998e-03\n",
      "  4.72392055e-02  7.61720754e-06  6.22259146e-03  1.03485776e-02\n",
      " -2.42525193e-04  6.76356867e-04 -4.78147780e-04 -6.55305512e-03\n",
      "  3.18891350e-01  2.07115807e-02 -7.62164146e-04 -1.25999002e-01\n",
      " -8.14298673e-03  4.64114044e-02 -1.48562041e-01  6.17285274e-03\n",
      "  4.72651750e-03  3.31069843e-03 -3.16467038e-02 -1.25220353e-05\n",
      "  7.37170240e-03 -2.68442970e-04 -8.14918399e-04  6.08584000e-03\n",
      "  1.07707043e-03  1.49557672e-02 -2.19614898e-05 -1.34310174e-04\n",
      "  2.26775959e-02]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "rr = Ridge(alpha = 5, max_iter = 100, tol = 0.1)\n",
    "rr.fit(X_train_poly,y_train)\n",
    "print('train score (L2) with polynomial features:',rr.score(X_train_poly, y_train))\n",
    "print('test score (L2) with polynomial features:',rr.score(X_test_poly, y_test))\n",
    "print('\\n')\n",
    "print(rr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae28591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b7ec5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "09107b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75550702, 0.6271085 , 0.7541725 , 0.78096855, 0.65941536])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross validation linear regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "rr = Ridge(alpha = 5, max_iter = 100, tol = 0.1)\n",
    "\n",
    "scores_rr = cross_val_score(rr, X_train, y_train, scoring='r2', cv=5)\n",
    "scores_rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "477e1edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72995813, 0.79398593, 0.73520035, 0.87590643, 0.81706584])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#perform cross validation in polynomial regression\n",
    "rr = Ridge(alpha = 5, max_iter = 100, tol = 0.1)\n",
    "scores_poly_rr = cross_val_score(rr, X_train_poly, y_train, scoring='r2', cv=5)\n",
    "scores_poly_rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40662b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af38651c",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning using gridsearchcv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "310405f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.19611579373923535, 0.6570541971408544)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lasso with linear features\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "lasso = Lasso()\n",
    "# lasso.fit(X_train, y_train)\n",
    "\n",
    "param_grid = {'alpha': [1,5,50,60,90,100],'tol':[0.1, 0.0001,0.001,0.01,0.2], 'max_iter':[10,50,100,500]}\n",
    "\n",
    "\n",
    "gs = GridSearchCV(lasso,param_grid,cv=10)\n",
    "gs.fit(X_train, y_train)\n",
    "gs.best_params_\n",
    "gs.cv_results_['mean_test_score'].min(), gs.cv_results_['mean_test_score'].max()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c14ddae",
   "metadata": {},
   "source": [
    "**scores near zero indicate poor performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c78b357e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7009177902665705, 0.8027631316630514)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# polynomial features\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "lasso = Lasso()\n",
    "\n",
    "param_grid = {'alpha': [1,5,50,60,90,100],'tol':[0.0001,0.001,0.01,0.1,0.2], 'max_iter':[10,50,100,500]}\n",
    "\n",
    "\n",
    "gs = GridSearchCV(lasso,param_grid,cv=10)\n",
    "gs.fit(X_train_poly, y_train)\n",
    "\n",
    "gs.best_params_\n",
    "\n",
    "gs.cv_results_['mean_test_score'].min(), gs.cv_results_['mean_test_score'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0eee2f",
   "metadata": {},
   "source": [
    "**scores closer to one indicates that the model performing better!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cfb8971a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1, 'max_iter': 10, 'tol': 0.0001}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6837988758705879, 0.695496021863359)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ridge\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rr = Ridge()\n",
    "\n",
    "param_grid = {'alpha': [1,5,50,60,90,100],'tol':[0.0001,0.001,0.01,0.1,0.2], 'max_iter':[10,50,100,500]}\n",
    "\n",
    "gs = GridSearchCV(rr,param_grid,cv=10)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_params_)\n",
    "gs.cv_results_['mean_test_score'].min(), gs.cv_results_['mean_test_score'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9ae6d9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 100, 'max_iter': 100, 'tol': 0.0001}\n",
      "\n",
      "minimum score is:  0.7649822428599264\n",
      "\n",
      "maximum score is:  0.7755505568143506 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_tol</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.775551</td>\n",
       "      <td>0.160309</td>\n",
       "      <td>0.847639</td>\n",
       "      <td>0.831140</td>\n",
       "      <td>0.901426</td>\n",
       "      <td>0.401851</td>\n",
       "      <td>0.580785</td>\n",
       "      <td>0.889397</td>\n",
       "      <td>0.899397</td>\n",
       "      <td>0.857694</td>\n",
       "      <td>0.873623</td>\n",
       "      <td>0.672553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1</td>\n",
       "      <td>0.775551</td>\n",
       "      <td>0.160309</td>\n",
       "      <td>0.847639</td>\n",
       "      <td>0.831140</td>\n",
       "      <td>0.901426</td>\n",
       "      <td>0.401851</td>\n",
       "      <td>0.580785</td>\n",
       "      <td>0.889397</td>\n",
       "      <td>0.899397</td>\n",
       "      <td>0.857694</td>\n",
       "      <td>0.873623</td>\n",
       "      <td>0.672553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>0.775551</td>\n",
       "      <td>0.160309</td>\n",
       "      <td>0.847639</td>\n",
       "      <td>0.831140</td>\n",
       "      <td>0.901426</td>\n",
       "      <td>0.401851</td>\n",
       "      <td>0.580785</td>\n",
       "      <td>0.889397</td>\n",
       "      <td>0.899397</td>\n",
       "      <td>0.857694</td>\n",
       "      <td>0.873623</td>\n",
       "      <td>0.672553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.775551</td>\n",
       "      <td>0.160309</td>\n",
       "      <td>0.847639</td>\n",
       "      <td>0.831140</td>\n",
       "      <td>0.901426</td>\n",
       "      <td>0.401851</td>\n",
       "      <td>0.580785</td>\n",
       "      <td>0.889397</td>\n",
       "      <td>0.899397</td>\n",
       "      <td>0.857694</td>\n",
       "      <td>0.873623</td>\n",
       "      <td>0.672553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.775551</td>\n",
       "      <td>0.160309</td>\n",
       "      <td>0.847639</td>\n",
       "      <td>0.831140</td>\n",
       "      <td>0.901426</td>\n",
       "      <td>0.401851</td>\n",
       "      <td>0.580785</td>\n",
       "      <td>0.889397</td>\n",
       "      <td>0.899397</td>\n",
       "      <td>0.857694</td>\n",
       "      <td>0.873623</td>\n",
       "      <td>0.672553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.775551</td>\n",
       "      <td>0.160309</td>\n",
       "      <td>0.847639</td>\n",
       "      <td>0.831140</td>\n",
       "      <td>0.901426</td>\n",
       "      <td>0.401851</td>\n",
       "      <td>0.580785</td>\n",
       "      <td>0.889397</td>\n",
       "      <td>0.899397</td>\n",
       "      <td>0.857694</td>\n",
       "      <td>0.873623</td>\n",
       "      <td>0.672553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1</td>\n",
       "      <td>0.775551</td>\n",
       "      <td>0.160309</td>\n",
       "      <td>0.847639</td>\n",
       "      <td>0.831140</td>\n",
       "      <td>0.901426</td>\n",
       "      <td>0.401851</td>\n",
       "      <td>0.580785</td>\n",
       "      <td>0.889397</td>\n",
       "      <td>0.899397</td>\n",
       "      <td>0.857694</td>\n",
       "      <td>0.873623</td>\n",
       "      <td>0.672553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>0.775551</td>\n",
       "      <td>0.160309</td>\n",
       "      <td>0.847639</td>\n",
       "      <td>0.831140</td>\n",
       "      <td>0.901426</td>\n",
       "      <td>0.401851</td>\n",
       "      <td>0.580785</td>\n",
       "      <td>0.889397</td>\n",
       "      <td>0.899397</td>\n",
       "      <td>0.857694</td>\n",
       "      <td>0.873623</td>\n",
       "      <td>0.672553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.775551</td>\n",
       "      <td>0.160309</td>\n",
       "      <td>0.847639</td>\n",
       "      <td>0.831140</td>\n",
       "      <td>0.901426</td>\n",
       "      <td>0.401851</td>\n",
       "      <td>0.580785</td>\n",
       "      <td>0.889397</td>\n",
       "      <td>0.899397</td>\n",
       "      <td>0.857694</td>\n",
       "      <td>0.873623</td>\n",
       "      <td>0.672553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.775551</td>\n",
       "      <td>0.160309</td>\n",
       "      <td>0.847639</td>\n",
       "      <td>0.831140</td>\n",
       "      <td>0.901426</td>\n",
       "      <td>0.401851</td>\n",
       "      <td>0.580785</td>\n",
       "      <td>0.889397</td>\n",
       "      <td>0.899397</td>\n",
       "      <td>0.857694</td>\n",
       "      <td>0.873623</td>\n",
       "      <td>0.672553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>90</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>11</td>\n",
       "      <td>0.775020</td>\n",
       "      <td>0.160645</td>\n",
       "      <td>0.846816</td>\n",
       "      <td>0.829674</td>\n",
       "      <td>0.901643</td>\n",
       "      <td>0.405458</td>\n",
       "      <td>0.571081</td>\n",
       "      <td>0.889404</td>\n",
       "      <td>0.899695</td>\n",
       "      <td>0.857419</td>\n",
       "      <td>0.875271</td>\n",
       "      <td>0.673741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>90</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>11</td>\n",
       "      <td>0.775020</td>\n",
       "      <td>0.160645</td>\n",
       "      <td>0.846816</td>\n",
       "      <td>0.829674</td>\n",
       "      <td>0.901643</td>\n",
       "      <td>0.405458</td>\n",
       "      <td>0.571081</td>\n",
       "      <td>0.889404</td>\n",
       "      <td>0.899695</td>\n",
       "      <td>0.857419</td>\n",
       "      <td>0.875271</td>\n",
       "      <td>0.673741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>90</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.775020</td>\n",
       "      <td>0.160645</td>\n",
       "      <td>0.846816</td>\n",
       "      <td>0.829674</td>\n",
       "      <td>0.901643</td>\n",
       "      <td>0.405458</td>\n",
       "      <td>0.571081</td>\n",
       "      <td>0.889404</td>\n",
       "      <td>0.899695</td>\n",
       "      <td>0.857419</td>\n",
       "      <td>0.875271</td>\n",
       "      <td>0.673741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>90</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>11</td>\n",
       "      <td>0.775020</td>\n",
       "      <td>0.160645</td>\n",
       "      <td>0.846816</td>\n",
       "      <td>0.829674</td>\n",
       "      <td>0.901643</td>\n",
       "      <td>0.405458</td>\n",
       "      <td>0.571081</td>\n",
       "      <td>0.889404</td>\n",
       "      <td>0.899695</td>\n",
       "      <td>0.857419</td>\n",
       "      <td>0.875271</td>\n",
       "      <td>0.673741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>90</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>11</td>\n",
       "      <td>0.775020</td>\n",
       "      <td>0.160645</td>\n",
       "      <td>0.846816</td>\n",
       "      <td>0.829674</td>\n",
       "      <td>0.901643</td>\n",
       "      <td>0.405458</td>\n",
       "      <td>0.571081</td>\n",
       "      <td>0.889404</td>\n",
       "      <td>0.899695</td>\n",
       "      <td>0.857419</td>\n",
       "      <td>0.875271</td>\n",
       "      <td>0.673741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>90</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>11</td>\n",
       "      <td>0.775020</td>\n",
       "      <td>0.160645</td>\n",
       "      <td>0.846816</td>\n",
       "      <td>0.829674</td>\n",
       "      <td>0.901643</td>\n",
       "      <td>0.405458</td>\n",
       "      <td>0.571081</td>\n",
       "      <td>0.889404</td>\n",
       "      <td>0.899695</td>\n",
       "      <td>0.857419</td>\n",
       "      <td>0.875271</td>\n",
       "      <td>0.673741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>90</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.775020</td>\n",
       "      <td>0.160645</td>\n",
       "      <td>0.846816</td>\n",
       "      <td>0.829674</td>\n",
       "      <td>0.901643</td>\n",
       "      <td>0.405458</td>\n",
       "      <td>0.571081</td>\n",
       "      <td>0.889404</td>\n",
       "      <td>0.899695</td>\n",
       "      <td>0.857419</td>\n",
       "      <td>0.875271</td>\n",
       "      <td>0.673741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>90</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>11</td>\n",
       "      <td>0.775020</td>\n",
       "      <td>0.160645</td>\n",
       "      <td>0.846816</td>\n",
       "      <td>0.829674</td>\n",
       "      <td>0.901643</td>\n",
       "      <td>0.405458</td>\n",
       "      <td>0.571081</td>\n",
       "      <td>0.889404</td>\n",
       "      <td>0.899695</td>\n",
       "      <td>0.857419</td>\n",
       "      <td>0.875271</td>\n",
       "      <td>0.673741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>90</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>11</td>\n",
       "      <td>0.775020</td>\n",
       "      <td>0.160645</td>\n",
       "      <td>0.846816</td>\n",
       "      <td>0.829674</td>\n",
       "      <td>0.901643</td>\n",
       "      <td>0.405458</td>\n",
       "      <td>0.571081</td>\n",
       "      <td>0.889404</td>\n",
       "      <td>0.899695</td>\n",
       "      <td>0.857419</td>\n",
       "      <td>0.875271</td>\n",
       "      <td>0.673741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>90</td>\n",
       "      <td>100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>11</td>\n",
       "      <td>0.775020</td>\n",
       "      <td>0.160645</td>\n",
       "      <td>0.846816</td>\n",
       "      <td>0.829674</td>\n",
       "      <td>0.901643</td>\n",
       "      <td>0.405458</td>\n",
       "      <td>0.571081</td>\n",
       "      <td>0.889404</td>\n",
       "      <td>0.899695</td>\n",
       "      <td>0.857419</td>\n",
       "      <td>0.875271</td>\n",
       "      <td>0.673741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>60</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>21</td>\n",
       "      <td>0.773490</td>\n",
       "      <td>0.161397</td>\n",
       "      <td>0.841244</td>\n",
       "      <td>0.824442</td>\n",
       "      <td>0.902276</td>\n",
       "      <td>0.420641</td>\n",
       "      <td>0.538525</td>\n",
       "      <td>0.889433</td>\n",
       "      <td>0.900681</td>\n",
       "      <td>0.856743</td>\n",
       "      <td>0.881349</td>\n",
       "      <td>0.679570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>21</td>\n",
       "      <td>0.773490</td>\n",
       "      <td>0.161397</td>\n",
       "      <td>0.841244</td>\n",
       "      <td>0.824442</td>\n",
       "      <td>0.902276</td>\n",
       "      <td>0.420641</td>\n",
       "      <td>0.538525</td>\n",
       "      <td>0.889433</td>\n",
       "      <td>0.900681</td>\n",
       "      <td>0.856743</td>\n",
       "      <td>0.881349</td>\n",
       "      <td>0.679570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>21</td>\n",
       "      <td>0.773490</td>\n",
       "      <td>0.161397</td>\n",
       "      <td>0.841244</td>\n",
       "      <td>0.824442</td>\n",
       "      <td>0.902276</td>\n",
       "      <td>0.420641</td>\n",
       "      <td>0.538525</td>\n",
       "      <td>0.889433</td>\n",
       "      <td>0.900681</td>\n",
       "      <td>0.856743</td>\n",
       "      <td>0.881349</td>\n",
       "      <td>0.679570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>21</td>\n",
       "      <td>0.773490</td>\n",
       "      <td>0.161397</td>\n",
       "      <td>0.841244</td>\n",
       "      <td>0.824442</td>\n",
       "      <td>0.902276</td>\n",
       "      <td>0.420641</td>\n",
       "      <td>0.538525</td>\n",
       "      <td>0.889433</td>\n",
       "      <td>0.900681</td>\n",
       "      <td>0.856743</td>\n",
       "      <td>0.881349</td>\n",
       "      <td>0.679570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>21</td>\n",
       "      <td>0.773490</td>\n",
       "      <td>0.161397</td>\n",
       "      <td>0.841244</td>\n",
       "      <td>0.824442</td>\n",
       "      <td>0.902276</td>\n",
       "      <td>0.420641</td>\n",
       "      <td>0.538525</td>\n",
       "      <td>0.889433</td>\n",
       "      <td>0.900681</td>\n",
       "      <td>0.856743</td>\n",
       "      <td>0.881349</td>\n",
       "      <td>0.679570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>21</td>\n",
       "      <td>0.773490</td>\n",
       "      <td>0.161397</td>\n",
       "      <td>0.841244</td>\n",
       "      <td>0.824442</td>\n",
       "      <td>0.902276</td>\n",
       "      <td>0.420641</td>\n",
       "      <td>0.538525</td>\n",
       "      <td>0.889433</td>\n",
       "      <td>0.900681</td>\n",
       "      <td>0.856743</td>\n",
       "      <td>0.881349</td>\n",
       "      <td>0.679570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>60</td>\n",
       "      <td>100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>21</td>\n",
       "      <td>0.773490</td>\n",
       "      <td>0.161397</td>\n",
       "      <td>0.841244</td>\n",
       "      <td>0.824442</td>\n",
       "      <td>0.902276</td>\n",
       "      <td>0.420641</td>\n",
       "      <td>0.538525</td>\n",
       "      <td>0.889433</td>\n",
       "      <td>0.900681</td>\n",
       "      <td>0.856743</td>\n",
       "      <td>0.881349</td>\n",
       "      <td>0.679570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>60</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>21</td>\n",
       "      <td>0.773490</td>\n",
       "      <td>0.161397</td>\n",
       "      <td>0.841244</td>\n",
       "      <td>0.824442</td>\n",
       "      <td>0.902276</td>\n",
       "      <td>0.420641</td>\n",
       "      <td>0.538525</td>\n",
       "      <td>0.889433</td>\n",
       "      <td>0.900681</td>\n",
       "      <td>0.856743</td>\n",
       "      <td>0.881349</td>\n",
       "      <td>0.679570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>60</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>21</td>\n",
       "      <td>0.773490</td>\n",
       "      <td>0.161397</td>\n",
       "      <td>0.841244</td>\n",
       "      <td>0.824442</td>\n",
       "      <td>0.902276</td>\n",
       "      <td>0.420641</td>\n",
       "      <td>0.538525</td>\n",
       "      <td>0.889433</td>\n",
       "      <td>0.900681</td>\n",
       "      <td>0.856743</td>\n",
       "      <td>0.881349</td>\n",
       "      <td>0.679570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>60</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>21</td>\n",
       "      <td>0.773490</td>\n",
       "      <td>0.161397</td>\n",
       "      <td>0.841244</td>\n",
       "      <td>0.824442</td>\n",
       "      <td>0.902276</td>\n",
       "      <td>0.420641</td>\n",
       "      <td>0.538525</td>\n",
       "      <td>0.889433</td>\n",
       "      <td>0.900681</td>\n",
       "      <td>0.856743</td>\n",
       "      <td>0.881349</td>\n",
       "      <td>0.679570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>31</td>\n",
       "      <td>0.773089</td>\n",
       "      <td>0.161397</td>\n",
       "      <td>0.837530</td>\n",
       "      <td>0.822278</td>\n",
       "      <td>0.902510</td>\n",
       "      <td>0.428009</td>\n",
       "      <td>0.526551</td>\n",
       "      <td>0.889528</td>\n",
       "      <td>0.901026</td>\n",
       "      <td>0.856634</td>\n",
       "      <td>0.883882</td>\n",
       "      <td>0.682945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>31</td>\n",
       "      <td>0.773089</td>\n",
       "      <td>0.161397</td>\n",
       "      <td>0.837530</td>\n",
       "      <td>0.822278</td>\n",
       "      <td>0.902510</td>\n",
       "      <td>0.428009</td>\n",
       "      <td>0.526551</td>\n",
       "      <td>0.889528</td>\n",
       "      <td>0.901026</td>\n",
       "      <td>0.856634</td>\n",
       "      <td>0.883882</td>\n",
       "      <td>0.682945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>31</td>\n",
       "      <td>0.773089</td>\n",
       "      <td>0.161397</td>\n",
       "      <td>0.837530</td>\n",
       "      <td>0.822278</td>\n",
       "      <td>0.902510</td>\n",
       "      <td>0.428009</td>\n",
       "      <td>0.526551</td>\n",
       "      <td>0.889528</td>\n",
       "      <td>0.901026</td>\n",
       "      <td>0.856634</td>\n",
       "      <td>0.883882</td>\n",
       "      <td>0.682945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>31</td>\n",
       "      <td>0.773089</td>\n",
       "      <td>0.161397</td>\n",
       "      <td>0.837530</td>\n",
       "      <td>0.822278</td>\n",
       "      <td>0.902510</td>\n",
       "      <td>0.428009</td>\n",
       "      <td>0.526551</td>\n",
       "      <td>0.889528</td>\n",
       "      <td>0.901026</td>\n",
       "      <td>0.856634</td>\n",
       "      <td>0.883882</td>\n",
       "      <td>0.682945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>31</td>\n",
       "      <td>0.773089</td>\n",
       "      <td>0.161397</td>\n",
       "      <td>0.837530</td>\n",
       "      <td>0.822278</td>\n",
       "      <td>0.902510</td>\n",
       "      <td>0.428009</td>\n",
       "      <td>0.526551</td>\n",
       "      <td>0.889528</td>\n",
       "      <td>0.901026</td>\n",
       "      <td>0.856634</td>\n",
       "      <td>0.883882</td>\n",
       "      <td>0.682945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>31</td>\n",
       "      <td>0.773089</td>\n",
       "      <td>0.161397</td>\n",
       "      <td>0.837530</td>\n",
       "      <td>0.822278</td>\n",
       "      <td>0.902510</td>\n",
       "      <td>0.428009</td>\n",
       "      <td>0.526551</td>\n",
       "      <td>0.889528</td>\n",
       "      <td>0.901026</td>\n",
       "      <td>0.856634</td>\n",
       "      <td>0.883882</td>\n",
       "      <td>0.682945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>31</td>\n",
       "      <td>0.773089</td>\n",
       "      <td>0.161397</td>\n",
       "      <td>0.837530</td>\n",
       "      <td>0.822278</td>\n",
       "      <td>0.902510</td>\n",
       "      <td>0.428009</td>\n",
       "      <td>0.526551</td>\n",
       "      <td>0.889528</td>\n",
       "      <td>0.901026</td>\n",
       "      <td>0.856634</td>\n",
       "      <td>0.883882</td>\n",
       "      <td>0.682945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>31</td>\n",
       "      <td>0.773089</td>\n",
       "      <td>0.161397</td>\n",
       "      <td>0.837530</td>\n",
       "      <td>0.822278</td>\n",
       "      <td>0.902510</td>\n",
       "      <td>0.428009</td>\n",
       "      <td>0.526551</td>\n",
       "      <td>0.889528</td>\n",
       "      <td>0.901026</td>\n",
       "      <td>0.856634</td>\n",
       "      <td>0.883882</td>\n",
       "      <td>0.682945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>31</td>\n",
       "      <td>0.773089</td>\n",
       "      <td>0.161397</td>\n",
       "      <td>0.837530</td>\n",
       "      <td>0.822278</td>\n",
       "      <td>0.902510</td>\n",
       "      <td>0.428009</td>\n",
       "      <td>0.526551</td>\n",
       "      <td>0.889528</td>\n",
       "      <td>0.901026</td>\n",
       "      <td>0.856634</td>\n",
       "      <td>0.883882</td>\n",
       "      <td>0.682945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>31</td>\n",
       "      <td>0.773089</td>\n",
       "      <td>0.161397</td>\n",
       "      <td>0.837530</td>\n",
       "      <td>0.822278</td>\n",
       "      <td>0.902510</td>\n",
       "      <td>0.428009</td>\n",
       "      <td>0.526551</td>\n",
       "      <td>0.889528</td>\n",
       "      <td>0.901026</td>\n",
       "      <td>0.856634</td>\n",
       "      <td>0.883882</td>\n",
       "      <td>0.682945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>41</td>\n",
       "      <td>0.772841</td>\n",
       "      <td>0.149059</td>\n",
       "      <td>0.730507</td>\n",
       "      <td>0.791354</td>\n",
       "      <td>0.907523</td>\n",
       "      <td>0.533896</td>\n",
       "      <td>0.471718</td>\n",
       "      <td>0.896205</td>\n",
       "      <td>0.898567</td>\n",
       "      <td>0.851735</td>\n",
       "      <td>0.900164</td>\n",
       "      <td>0.746742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>41</td>\n",
       "      <td>0.772841</td>\n",
       "      <td>0.149059</td>\n",
       "      <td>0.730507</td>\n",
       "      <td>0.791354</td>\n",
       "      <td>0.907523</td>\n",
       "      <td>0.533896</td>\n",
       "      <td>0.471718</td>\n",
       "      <td>0.896205</td>\n",
       "      <td>0.898567</td>\n",
       "      <td>0.851735</td>\n",
       "      <td>0.900164</td>\n",
       "      <td>0.746742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>41</td>\n",
       "      <td>0.772841</td>\n",
       "      <td>0.149059</td>\n",
       "      <td>0.730507</td>\n",
       "      <td>0.791354</td>\n",
       "      <td>0.907523</td>\n",
       "      <td>0.533896</td>\n",
       "      <td>0.471718</td>\n",
       "      <td>0.896205</td>\n",
       "      <td>0.898567</td>\n",
       "      <td>0.851735</td>\n",
       "      <td>0.900164</td>\n",
       "      <td>0.746742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>41</td>\n",
       "      <td>0.772841</td>\n",
       "      <td>0.149059</td>\n",
       "      <td>0.730507</td>\n",
       "      <td>0.791354</td>\n",
       "      <td>0.907523</td>\n",
       "      <td>0.533896</td>\n",
       "      <td>0.471718</td>\n",
       "      <td>0.896205</td>\n",
       "      <td>0.898567</td>\n",
       "      <td>0.851735</td>\n",
       "      <td>0.900164</td>\n",
       "      <td>0.746742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>41</td>\n",
       "      <td>0.772841</td>\n",
       "      <td>0.149059</td>\n",
       "      <td>0.730507</td>\n",
       "      <td>0.791354</td>\n",
       "      <td>0.907523</td>\n",
       "      <td>0.533896</td>\n",
       "      <td>0.471718</td>\n",
       "      <td>0.896205</td>\n",
       "      <td>0.898567</td>\n",
       "      <td>0.851735</td>\n",
       "      <td>0.900164</td>\n",
       "      <td>0.746742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>41</td>\n",
       "      <td>0.772841</td>\n",
       "      <td>0.149059</td>\n",
       "      <td>0.730507</td>\n",
       "      <td>0.791354</td>\n",
       "      <td>0.907523</td>\n",
       "      <td>0.533896</td>\n",
       "      <td>0.471718</td>\n",
       "      <td>0.896205</td>\n",
       "      <td>0.898567</td>\n",
       "      <td>0.851735</td>\n",
       "      <td>0.900164</td>\n",
       "      <td>0.746742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>41</td>\n",
       "      <td>0.772841</td>\n",
       "      <td>0.149059</td>\n",
       "      <td>0.730507</td>\n",
       "      <td>0.791354</td>\n",
       "      <td>0.907523</td>\n",
       "      <td>0.533896</td>\n",
       "      <td>0.471718</td>\n",
       "      <td>0.896205</td>\n",
       "      <td>0.898567</td>\n",
       "      <td>0.851735</td>\n",
       "      <td>0.900164</td>\n",
       "      <td>0.746742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>41</td>\n",
       "      <td>0.772841</td>\n",
       "      <td>0.149059</td>\n",
       "      <td>0.730507</td>\n",
       "      <td>0.791354</td>\n",
       "      <td>0.907523</td>\n",
       "      <td>0.533896</td>\n",
       "      <td>0.471718</td>\n",
       "      <td>0.896205</td>\n",
       "      <td>0.898567</td>\n",
       "      <td>0.851735</td>\n",
       "      <td>0.900164</td>\n",
       "      <td>0.746742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>41</td>\n",
       "      <td>0.772841</td>\n",
       "      <td>0.149059</td>\n",
       "      <td>0.730507</td>\n",
       "      <td>0.791354</td>\n",
       "      <td>0.907523</td>\n",
       "      <td>0.533896</td>\n",
       "      <td>0.471718</td>\n",
       "      <td>0.896205</td>\n",
       "      <td>0.898567</td>\n",
       "      <td>0.851735</td>\n",
       "      <td>0.900164</td>\n",
       "      <td>0.746742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>41</td>\n",
       "      <td>0.772841</td>\n",
       "      <td>0.149059</td>\n",
       "      <td>0.730507</td>\n",
       "      <td>0.791354</td>\n",
       "      <td>0.907523</td>\n",
       "      <td>0.533896</td>\n",
       "      <td>0.471718</td>\n",
       "      <td>0.896205</td>\n",
       "      <td>0.898567</td>\n",
       "      <td>0.851735</td>\n",
       "      <td>0.900164</td>\n",
       "      <td>0.746742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>51</td>\n",
       "      <td>0.764982</td>\n",
       "      <td>0.148426</td>\n",
       "      <td>0.637390</td>\n",
       "      <td>0.773889</td>\n",
       "      <td>0.911308</td>\n",
       "      <td>0.598987</td>\n",
       "      <td>0.448036</td>\n",
       "      <td>0.885226</td>\n",
       "      <td>0.893836</td>\n",
       "      <td>0.832463</td>\n",
       "      <td>0.902480</td>\n",
       "      <td>0.766207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>51</td>\n",
       "      <td>0.764982</td>\n",
       "      <td>0.148426</td>\n",
       "      <td>0.637390</td>\n",
       "      <td>0.773889</td>\n",
       "      <td>0.911308</td>\n",
       "      <td>0.598987</td>\n",
       "      <td>0.448036</td>\n",
       "      <td>0.885226</td>\n",
       "      <td>0.893836</td>\n",
       "      <td>0.832463</td>\n",
       "      <td>0.902480</td>\n",
       "      <td>0.766207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>51</td>\n",
       "      <td>0.764982</td>\n",
       "      <td>0.148426</td>\n",
       "      <td>0.637390</td>\n",
       "      <td>0.773889</td>\n",
       "      <td>0.911308</td>\n",
       "      <td>0.598987</td>\n",
       "      <td>0.448036</td>\n",
       "      <td>0.885226</td>\n",
       "      <td>0.893836</td>\n",
       "      <td>0.832463</td>\n",
       "      <td>0.902480</td>\n",
       "      <td>0.766207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>51</td>\n",
       "      <td>0.764982</td>\n",
       "      <td>0.148426</td>\n",
       "      <td>0.637390</td>\n",
       "      <td>0.773889</td>\n",
       "      <td>0.911308</td>\n",
       "      <td>0.598987</td>\n",
       "      <td>0.448036</td>\n",
       "      <td>0.885226</td>\n",
       "      <td>0.893836</td>\n",
       "      <td>0.832463</td>\n",
       "      <td>0.902480</td>\n",
       "      <td>0.766207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>51</td>\n",
       "      <td>0.764982</td>\n",
       "      <td>0.148426</td>\n",
       "      <td>0.637390</td>\n",
       "      <td>0.773889</td>\n",
       "      <td>0.911308</td>\n",
       "      <td>0.598987</td>\n",
       "      <td>0.448036</td>\n",
       "      <td>0.885226</td>\n",
       "      <td>0.893836</td>\n",
       "      <td>0.832463</td>\n",
       "      <td>0.902480</td>\n",
       "      <td>0.766207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>51</td>\n",
       "      <td>0.764982</td>\n",
       "      <td>0.148426</td>\n",
       "      <td>0.637390</td>\n",
       "      <td>0.773889</td>\n",
       "      <td>0.911308</td>\n",
       "      <td>0.598987</td>\n",
       "      <td>0.448036</td>\n",
       "      <td>0.885226</td>\n",
       "      <td>0.893836</td>\n",
       "      <td>0.832463</td>\n",
       "      <td>0.902480</td>\n",
       "      <td>0.766207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>51</td>\n",
       "      <td>0.764982</td>\n",
       "      <td>0.148426</td>\n",
       "      <td>0.637390</td>\n",
       "      <td>0.773889</td>\n",
       "      <td>0.911308</td>\n",
       "      <td>0.598987</td>\n",
       "      <td>0.448036</td>\n",
       "      <td>0.885226</td>\n",
       "      <td>0.893836</td>\n",
       "      <td>0.832463</td>\n",
       "      <td>0.902480</td>\n",
       "      <td>0.766207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>51</td>\n",
       "      <td>0.764982</td>\n",
       "      <td>0.148426</td>\n",
       "      <td>0.637390</td>\n",
       "      <td>0.773889</td>\n",
       "      <td>0.911308</td>\n",
       "      <td>0.598987</td>\n",
       "      <td>0.448036</td>\n",
       "      <td>0.885226</td>\n",
       "      <td>0.893836</td>\n",
       "      <td>0.832463</td>\n",
       "      <td>0.902480</td>\n",
       "      <td>0.766207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>51</td>\n",
       "      <td>0.764982</td>\n",
       "      <td>0.148426</td>\n",
       "      <td>0.637390</td>\n",
       "      <td>0.773889</td>\n",
       "      <td>0.911308</td>\n",
       "      <td>0.598987</td>\n",
       "      <td>0.448036</td>\n",
       "      <td>0.885226</td>\n",
       "      <td>0.893836</td>\n",
       "      <td>0.832463</td>\n",
       "      <td>0.902480</td>\n",
       "      <td>0.766207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>51</td>\n",
       "      <td>0.764982</td>\n",
       "      <td>0.148426</td>\n",
       "      <td>0.637390</td>\n",
       "      <td>0.773889</td>\n",
       "      <td>0.911308</td>\n",
       "      <td>0.598987</td>\n",
       "      <td>0.448036</td>\n",
       "      <td>0.885226</td>\n",
       "      <td>0.893836</td>\n",
       "      <td>0.832463</td>\n",
       "      <td>0.902480</td>\n",
       "      <td>0.766207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_alpha param_max_iter param_tol  rank_test_score  mean_test_score  \\\n",
       "59         100             10       0.2                1         0.775551   \n",
       "50         100            100    0.0001                1         0.775551   \n",
       "51         100            100     0.001                1         0.775551   \n",
       "52         100            100      0.01                1         0.775551   \n",
       "53         100            100       0.1                1         0.775551   \n",
       "58         100             10       0.1                1         0.775551   \n",
       "55         100             10    0.0001                1         0.775551   \n",
       "56         100             10     0.001                1         0.775551   \n",
       "57         100             10      0.01                1         0.775551   \n",
       "54         100            100       0.2                1         0.775551   \n",
       "40          90            100    0.0001               11         0.775020   \n",
       "42          90            100      0.01               11         0.775020   \n",
       "43          90            100       0.1               11         0.775020   \n",
       "41          90            100     0.001               11         0.775020   \n",
       "46          90             10     0.001               11         0.775020   \n",
       "47          90             10      0.01               11         0.775020   \n",
       "48          90             10       0.1               11         0.775020   \n",
       "49          90             10       0.2               11         0.775020   \n",
       "45          90             10    0.0001               11         0.775020   \n",
       "44          90            100       0.2               11         0.775020   \n",
       "30          60            100    0.0001               21         0.773490   \n",
       "39          60             10       0.2               21         0.773490   \n",
       "38          60             10       0.1               21         0.773490   \n",
       "37          60             10      0.01               21         0.773490   \n",
       "36          60             10     0.001               21         0.773490   \n",
       "35          60             10    0.0001               21         0.773490   \n",
       "34          60            100       0.2               21         0.773490   \n",
       "33          60            100       0.1               21         0.773490   \n",
       "32          60            100      0.01               21         0.773490   \n",
       "31          60            100     0.001               21         0.773490   \n",
       "29          50             10       0.2               31         0.773089   \n",
       "27          50             10      0.01               31         0.773089   \n",
       "26          50             10     0.001               31         0.773089   \n",
       "25          50             10    0.0001               31         0.773089   \n",
       "24          50            100       0.2               31         0.773089   \n",
       "23          50            100       0.1               31         0.773089   \n",
       "22          50            100      0.01               31         0.773089   \n",
       "21          50            100     0.001               31         0.773089   \n",
       "20          50            100    0.0001               31         0.773089   \n",
       "28          50             10       0.1               31         0.773089   \n",
       "10           5            100    0.0001               41         0.772841   \n",
       "11           5            100     0.001               41         0.772841   \n",
       "12           5            100      0.01               41         0.772841   \n",
       "14           5            100       0.2               41         0.772841   \n",
       "13           5            100       0.1               41         0.772841   \n",
       "16           5             10     0.001               41         0.772841   \n",
       "17           5             10      0.01               41         0.772841   \n",
       "18           5             10       0.1               41         0.772841   \n",
       "19           5             10       0.2               41         0.772841   \n",
       "15           5             10    0.0001               41         0.772841   \n",
       "9            1             10       0.2               51         0.764982   \n",
       "8            1             10       0.1               51         0.764982   \n",
       "7            1             10      0.01               51         0.764982   \n",
       "6            1             10     0.001               51         0.764982   \n",
       "5            1             10    0.0001               51         0.764982   \n",
       "4            1            100       0.2               51         0.764982   \n",
       "3            1            100       0.1               51         0.764982   \n",
       "2            1            100      0.01               51         0.764982   \n",
       "1            1            100     0.001               51         0.764982   \n",
       "0            1            100    0.0001               51         0.764982   \n",
       "\n",
       "    std_test_score  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "59        0.160309           0.847639           0.831140           0.901426   \n",
       "50        0.160309           0.847639           0.831140           0.901426   \n",
       "51        0.160309           0.847639           0.831140           0.901426   \n",
       "52        0.160309           0.847639           0.831140           0.901426   \n",
       "53        0.160309           0.847639           0.831140           0.901426   \n",
       "58        0.160309           0.847639           0.831140           0.901426   \n",
       "55        0.160309           0.847639           0.831140           0.901426   \n",
       "56        0.160309           0.847639           0.831140           0.901426   \n",
       "57        0.160309           0.847639           0.831140           0.901426   \n",
       "54        0.160309           0.847639           0.831140           0.901426   \n",
       "40        0.160645           0.846816           0.829674           0.901643   \n",
       "42        0.160645           0.846816           0.829674           0.901643   \n",
       "43        0.160645           0.846816           0.829674           0.901643   \n",
       "41        0.160645           0.846816           0.829674           0.901643   \n",
       "46        0.160645           0.846816           0.829674           0.901643   \n",
       "47        0.160645           0.846816           0.829674           0.901643   \n",
       "48        0.160645           0.846816           0.829674           0.901643   \n",
       "49        0.160645           0.846816           0.829674           0.901643   \n",
       "45        0.160645           0.846816           0.829674           0.901643   \n",
       "44        0.160645           0.846816           0.829674           0.901643   \n",
       "30        0.161397           0.841244           0.824442           0.902276   \n",
       "39        0.161397           0.841244           0.824442           0.902276   \n",
       "38        0.161397           0.841244           0.824442           0.902276   \n",
       "37        0.161397           0.841244           0.824442           0.902276   \n",
       "36        0.161397           0.841244           0.824442           0.902276   \n",
       "35        0.161397           0.841244           0.824442           0.902276   \n",
       "34        0.161397           0.841244           0.824442           0.902276   \n",
       "33        0.161397           0.841244           0.824442           0.902276   \n",
       "32        0.161397           0.841244           0.824442           0.902276   \n",
       "31        0.161397           0.841244           0.824442           0.902276   \n",
       "29        0.161397           0.837530           0.822278           0.902510   \n",
       "27        0.161397           0.837530           0.822278           0.902510   \n",
       "26        0.161397           0.837530           0.822278           0.902510   \n",
       "25        0.161397           0.837530           0.822278           0.902510   \n",
       "24        0.161397           0.837530           0.822278           0.902510   \n",
       "23        0.161397           0.837530           0.822278           0.902510   \n",
       "22        0.161397           0.837530           0.822278           0.902510   \n",
       "21        0.161397           0.837530           0.822278           0.902510   \n",
       "20        0.161397           0.837530           0.822278           0.902510   \n",
       "28        0.161397           0.837530           0.822278           0.902510   \n",
       "10        0.149059           0.730507           0.791354           0.907523   \n",
       "11        0.149059           0.730507           0.791354           0.907523   \n",
       "12        0.149059           0.730507           0.791354           0.907523   \n",
       "14        0.149059           0.730507           0.791354           0.907523   \n",
       "13        0.149059           0.730507           0.791354           0.907523   \n",
       "16        0.149059           0.730507           0.791354           0.907523   \n",
       "17        0.149059           0.730507           0.791354           0.907523   \n",
       "18        0.149059           0.730507           0.791354           0.907523   \n",
       "19        0.149059           0.730507           0.791354           0.907523   \n",
       "15        0.149059           0.730507           0.791354           0.907523   \n",
       "9         0.148426           0.637390           0.773889           0.911308   \n",
       "8         0.148426           0.637390           0.773889           0.911308   \n",
       "7         0.148426           0.637390           0.773889           0.911308   \n",
       "6         0.148426           0.637390           0.773889           0.911308   \n",
       "5         0.148426           0.637390           0.773889           0.911308   \n",
       "4         0.148426           0.637390           0.773889           0.911308   \n",
       "3         0.148426           0.637390           0.773889           0.911308   \n",
       "2         0.148426           0.637390           0.773889           0.911308   \n",
       "1         0.148426           0.637390           0.773889           0.911308   \n",
       "0         0.148426           0.637390           0.773889           0.911308   \n",
       "\n",
       "    split3_test_score  split4_test_score  split5_test_score  \\\n",
       "59           0.401851           0.580785           0.889397   \n",
       "50           0.401851           0.580785           0.889397   \n",
       "51           0.401851           0.580785           0.889397   \n",
       "52           0.401851           0.580785           0.889397   \n",
       "53           0.401851           0.580785           0.889397   \n",
       "58           0.401851           0.580785           0.889397   \n",
       "55           0.401851           0.580785           0.889397   \n",
       "56           0.401851           0.580785           0.889397   \n",
       "57           0.401851           0.580785           0.889397   \n",
       "54           0.401851           0.580785           0.889397   \n",
       "40           0.405458           0.571081           0.889404   \n",
       "42           0.405458           0.571081           0.889404   \n",
       "43           0.405458           0.571081           0.889404   \n",
       "41           0.405458           0.571081           0.889404   \n",
       "46           0.405458           0.571081           0.889404   \n",
       "47           0.405458           0.571081           0.889404   \n",
       "48           0.405458           0.571081           0.889404   \n",
       "49           0.405458           0.571081           0.889404   \n",
       "45           0.405458           0.571081           0.889404   \n",
       "44           0.405458           0.571081           0.889404   \n",
       "30           0.420641           0.538525           0.889433   \n",
       "39           0.420641           0.538525           0.889433   \n",
       "38           0.420641           0.538525           0.889433   \n",
       "37           0.420641           0.538525           0.889433   \n",
       "36           0.420641           0.538525           0.889433   \n",
       "35           0.420641           0.538525           0.889433   \n",
       "34           0.420641           0.538525           0.889433   \n",
       "33           0.420641           0.538525           0.889433   \n",
       "32           0.420641           0.538525           0.889433   \n",
       "31           0.420641           0.538525           0.889433   \n",
       "29           0.428009           0.526551           0.889528   \n",
       "27           0.428009           0.526551           0.889528   \n",
       "26           0.428009           0.526551           0.889528   \n",
       "25           0.428009           0.526551           0.889528   \n",
       "24           0.428009           0.526551           0.889528   \n",
       "23           0.428009           0.526551           0.889528   \n",
       "22           0.428009           0.526551           0.889528   \n",
       "21           0.428009           0.526551           0.889528   \n",
       "20           0.428009           0.526551           0.889528   \n",
       "28           0.428009           0.526551           0.889528   \n",
       "10           0.533896           0.471718           0.896205   \n",
       "11           0.533896           0.471718           0.896205   \n",
       "12           0.533896           0.471718           0.896205   \n",
       "14           0.533896           0.471718           0.896205   \n",
       "13           0.533896           0.471718           0.896205   \n",
       "16           0.533896           0.471718           0.896205   \n",
       "17           0.533896           0.471718           0.896205   \n",
       "18           0.533896           0.471718           0.896205   \n",
       "19           0.533896           0.471718           0.896205   \n",
       "15           0.533896           0.471718           0.896205   \n",
       "9            0.598987           0.448036           0.885226   \n",
       "8            0.598987           0.448036           0.885226   \n",
       "7            0.598987           0.448036           0.885226   \n",
       "6            0.598987           0.448036           0.885226   \n",
       "5            0.598987           0.448036           0.885226   \n",
       "4            0.598987           0.448036           0.885226   \n",
       "3            0.598987           0.448036           0.885226   \n",
       "2            0.598987           0.448036           0.885226   \n",
       "1            0.598987           0.448036           0.885226   \n",
       "0            0.598987           0.448036           0.885226   \n",
       "\n",
       "    split6_test_score  split7_test_score  split8_test_score  split9_test_score  \n",
       "59           0.899397           0.857694           0.873623           0.672553  \n",
       "50           0.899397           0.857694           0.873623           0.672553  \n",
       "51           0.899397           0.857694           0.873623           0.672553  \n",
       "52           0.899397           0.857694           0.873623           0.672553  \n",
       "53           0.899397           0.857694           0.873623           0.672553  \n",
       "58           0.899397           0.857694           0.873623           0.672553  \n",
       "55           0.899397           0.857694           0.873623           0.672553  \n",
       "56           0.899397           0.857694           0.873623           0.672553  \n",
       "57           0.899397           0.857694           0.873623           0.672553  \n",
       "54           0.899397           0.857694           0.873623           0.672553  \n",
       "40           0.899695           0.857419           0.875271           0.673741  \n",
       "42           0.899695           0.857419           0.875271           0.673741  \n",
       "43           0.899695           0.857419           0.875271           0.673741  \n",
       "41           0.899695           0.857419           0.875271           0.673741  \n",
       "46           0.899695           0.857419           0.875271           0.673741  \n",
       "47           0.899695           0.857419           0.875271           0.673741  \n",
       "48           0.899695           0.857419           0.875271           0.673741  \n",
       "49           0.899695           0.857419           0.875271           0.673741  \n",
       "45           0.899695           0.857419           0.875271           0.673741  \n",
       "44           0.899695           0.857419           0.875271           0.673741  \n",
       "30           0.900681           0.856743           0.881349           0.679570  \n",
       "39           0.900681           0.856743           0.881349           0.679570  \n",
       "38           0.900681           0.856743           0.881349           0.679570  \n",
       "37           0.900681           0.856743           0.881349           0.679570  \n",
       "36           0.900681           0.856743           0.881349           0.679570  \n",
       "35           0.900681           0.856743           0.881349           0.679570  \n",
       "34           0.900681           0.856743           0.881349           0.679570  \n",
       "33           0.900681           0.856743           0.881349           0.679570  \n",
       "32           0.900681           0.856743           0.881349           0.679570  \n",
       "31           0.900681           0.856743           0.881349           0.679570  \n",
       "29           0.901026           0.856634           0.883882           0.682945  \n",
       "27           0.901026           0.856634           0.883882           0.682945  \n",
       "26           0.901026           0.856634           0.883882           0.682945  \n",
       "25           0.901026           0.856634           0.883882           0.682945  \n",
       "24           0.901026           0.856634           0.883882           0.682945  \n",
       "23           0.901026           0.856634           0.883882           0.682945  \n",
       "22           0.901026           0.856634           0.883882           0.682945  \n",
       "21           0.901026           0.856634           0.883882           0.682945  \n",
       "20           0.901026           0.856634           0.883882           0.682945  \n",
       "28           0.901026           0.856634           0.883882           0.682945  \n",
       "10           0.898567           0.851735           0.900164           0.746742  \n",
       "11           0.898567           0.851735           0.900164           0.746742  \n",
       "12           0.898567           0.851735           0.900164           0.746742  \n",
       "14           0.898567           0.851735           0.900164           0.746742  \n",
       "13           0.898567           0.851735           0.900164           0.746742  \n",
       "16           0.898567           0.851735           0.900164           0.746742  \n",
       "17           0.898567           0.851735           0.900164           0.746742  \n",
       "18           0.898567           0.851735           0.900164           0.746742  \n",
       "19           0.898567           0.851735           0.900164           0.746742  \n",
       "15           0.898567           0.851735           0.900164           0.746742  \n",
       "9            0.893836           0.832463           0.902480           0.766207  \n",
       "8            0.893836           0.832463           0.902480           0.766207  \n",
       "7            0.893836           0.832463           0.902480           0.766207  \n",
       "6            0.893836           0.832463           0.902480           0.766207  \n",
       "5            0.893836           0.832463           0.902480           0.766207  \n",
       "4            0.893836           0.832463           0.902480           0.766207  \n",
       "3            0.893836           0.832463           0.902480           0.766207  \n",
       "2            0.893836           0.832463           0.902480           0.766207  \n",
       "1            0.893836           0.832463           0.902480           0.766207  \n",
       "0            0.893836           0.832463           0.902480           0.766207  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['param_alpha', 'param_max_iter', 'param_tol', 'rank_test_score',\n",
      "       'mean_test_score', 'std_test_score', 'split0_test_score',\n",
      "       'split1_test_score', 'split2_test_score', 'split3_test_score',\n",
      "       'split4_test_score', 'split5_test_score', 'split6_test_score',\n",
      "       'split7_test_score', 'split8_test_score', 'split9_test_score'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rr = Ridge()\n",
    "\n",
    "param_grid = {'alpha': [1,5,50,60,90,100],'tol':[0.0001,0.001,0.01,0.1,0.2], 'max_iter':[100,10]}\n",
    "\n",
    "gs = GridSearchCV(rr,param_grid,cv=10)\n",
    "\n",
    "gs.fit(X_train_poly, y_train)\n",
    "print(gs.best_params_)\n",
    "print('\\nminimum score is: ', gs.cv_results_['mean_test_score'].min())\n",
    "print('\\nmaximum score is: ', gs.cv_results_['mean_test_score'].max(),'\\n')\n",
    "# print(gs.cv_results_['mean_test_score'])\n",
    "\n",
    "cv_result = pd.DataFrame(gs.cv_results_)\n",
    "cv_result = cv_result[['param_alpha', 'param_max_iter','param_tol','rank_test_score', \n",
    "                       'mean_test_score', 'std_test_score','split0_test_score',\n",
    "                       'split1_test_score', 'split2_test_score', 'split3_test_score',\n",
    "                       'split4_test_score','split5_test_score','split6_test_score',\n",
    "                       'split7_test_score','split8_test_score','split9_test_score']]\n",
    "cv_result = cv_result.sort_values(by='rank_test_score')\n",
    "display(cv_result)\n",
    "print(cv_result.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852ab6c9",
   "metadata": {},
   "source": [
    "**We perform multiple linear regression to predict the house price based on the given features. The performance indicates model is probably underfitted. we then tried polynomial regression and found that this model is overfitted. to overcome overfitting issue we apply regularization techniques L1 and L2 and found that L2 (Ridge) regularization with polynomial feature perform better in this perticular case. After that we perform hyperparameter tuning to obtain the optimum model.\n",
    "<br>Finally we got best regression model with optimum hyperparameters applying L2 with polynomial features.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3095ab9",
   "metadata": {},
   "source": [
    "## Model performance evaluation with the best found model in grid search and cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "504a77e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 100, 'max_iter': 100, 'tol': 0.0001}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.808931910430797"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr = Ridge()\n",
    "gs = GridSearchCV(rr,param_grid,cv=10)\n",
    "gs.fit(X_train_poly, y_train)\n",
    "print(gs.best_params_)\n",
    "\n",
    "# test score using best found model\n",
    "gs.score(X_test_poly,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03bf423",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46d36dc8",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b685a510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 100, 'max_iter': 100, 'tol': 0.0001}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price_actual</th>\n",
       "      <th>Price_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>23.6</td>\n",
       "      <td>26.477159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>32.4</td>\n",
       "      <td>33.583371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>13.6</td>\n",
       "      <td>14.979459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>22.8</td>\n",
       "      <td>21.834182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>16.1</td>\n",
       "      <td>15.182430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>17.9</td>\n",
       "      <td>13.497873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>9.6</td>\n",
       "      <td>12.432217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>17.2</td>\n",
       "      <td>14.941107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>22.5</td>\n",
       "      <td>23.755274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>21.4</td>\n",
       "      <td>23.110479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Price_actual  Price_predicted\n",
       "173          23.6        26.477159\n",
       "274          32.4        33.583371\n",
       "491          13.6        14.979459\n",
       "72           22.8        21.834182\n",
       "452          16.1        15.182430\n",
       "..            ...              ...\n",
       "412          17.9        13.497873\n",
       "436           9.6        12.432217\n",
       "411          17.2        14.941107\n",
       "86           22.5        23.755274\n",
       "75           21.4        23.110479\n",
       "\n",
       "[102 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rr = Ridge()\n",
    "gs = GridSearchCV(rr,param_grid,cv=10)\n",
    "gs.fit(X_train_poly, y_train)\n",
    "print(gs.best_params_)\n",
    "\n",
    "# predict y value with test feature values using best found model\n",
    "\n",
    "y_pred = gs.predict(X_test_poly)\n",
    "\n",
    "price = pd.DataFrame({\"Price_actual\":y_test,\n",
    "                   \"Price_predicted\": y_pred})\n",
    "\n",
    "display(price)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100b5a03",
   "metadata": {},
   "source": [
    "#### Prediction Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "68048922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE =  2.486093786732154\n",
      "MSE =  14.011745849325095\n",
      "RMSE =  3.743226662830491\n",
      "r_squared =  0.808931910430797\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "MAE = mean_absolute_error(y_test, y_pred)\n",
    "print(\"MAE = \", MAE)\n",
    "\n",
    "MSE = mean_squared_error(y_test, y_pred, squared=True)\n",
    "print(\"MSE = \", MSE)\n",
    "\n",
    "RMSE = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(\"RMSE = \", RMSE)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"r_squared = \", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7bbbca",
   "metadata": {},
   "source": [
    "**Mean absolute error** represents the average of the absolute difference between the actual and predicted values in the dataset. It measures the average of the residuals in the dataset.\n",
    "<br>**Mean Squared Error** represents the average of the squared difference between the original and predicted values in the data set. It measures the variance of the residuals.\n",
    "<br>**Root Mean Squared Error** is the square root of Mean Squared error. It measures the standard deviation of residuals.\n",
    "<br>**Coefficient of determination or R-squared** represents the proportion of the variance in the dependent variable. It is a scale-free score i.e. irrespective of the values being small or large, the value of R square will be less than one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8738e5",
   "metadata": {},
   "source": [
    "## How to get the regression coefficients of finally selected model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8f78945e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 100, 'max_iter': 100, 'tol': 0.0001}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "164ca915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-27.24335333843289\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00, -1.53284134e-02, -1.09560926e-01, -2.26421226e-02,\n",
       "       -2.50518882e-04,  7.16292976e-03,  1.02792132e-01,  1.55800322e-01,\n",
       "       -2.85927281e-02,  6.56792986e-02,  3.05288486e-03, -7.63406798e-02,\n",
       "        1.76174962e-01, -9.03682722e-02, -1.72137574e-04,  5.85451023e-02,\n",
       "        6.28337675e-02,  7.42888422e-01, -1.04020745e-01,  1.79241966e-01,\n",
       "       -1.84134426e-03, -3.75244800e-02, -1.35399594e-02, -3.12065735e-03,\n",
       "        3.69942998e-03, -3.39099814e-04,  1.93914375e-02,  5.01748577e-04,\n",
       "        9.54924266e-04, -2.21283237e-03,  6.17781249e-02,  1.03184889e-02,\n",
       "        6.56346484e-04, -1.29039129e-02, -1.20943676e-02,  4.62138351e-04,\n",
       "        7.80581274e-03, -3.95405340e-04, -8.08923642e-03,  2.55534525e-02,\n",
       "       -6.73723090e-02,  3.81015339e-02, -5.21572782e-03,  5.58121000e-03,\n",
       "        1.28055184e-02,  1.21929258e-02,  1.18318974e-03, -6.24314639e-02,\n",
       "        2.23009248e-05, -2.65375923e-02, -2.50518882e-04, -2.68817728e-02,\n",
       "       -3.60437884e-01, -2.80418725e-04, -7.39835460e-02,  1.13579720e-01,\n",
       "       -5.01128530e-03,  1.04922219e-01,  8.39615325e-03, -9.32285736e-02,\n",
       "        4.94703479e-03,  5.87229510e-02,  6.94063227e-02,  6.50174034e-02,\n",
       "       -8.85247852e-02, -5.13986528e-02,  4.63788962e-02,  9.94697345e-04,\n",
       "        2.12307978e-01,  9.48699609e-01, -8.84647830e-03,  1.44158574e-01,\n",
       "       -3.46996253e-01, -4.92068429e-03, -1.22529218e-01, -1.39272887e-04,\n",
       "       -1.58953964e-03, -2.25111971e-04,  9.51881400e-03,  7.39021656e-03,\n",
       "       -2.26684184e-04,  3.40196501e-03, -6.08108174e-04, -5.00404127e-03,\n",
       "        2.84790545e-01, -7.17938932e-03, -6.99472235e-04, -1.09484693e-01,\n",
       "       -8.73790874e-03,  3.39388439e-02, -1.52554029e-01,  5.97618550e-03,\n",
       "        7.90126351e-02,  2.43856029e-03, -3.00768431e-02, -2.11128427e-05,\n",
       "        6.19944893e-03, -2.03515957e-04, -7.71267706e-04, -3.35584348e-02,\n",
       "       -1.70011474e-04,  6.59120068e-03, -2.08815648e-05, -3.86174630e-04,\n",
       "        2.53910127e-02])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr_final=Ridge(alpha= 100, max_iter= 100, tol= 0.0001)\n",
    "rr_final.fit(X_train_poly,y_train)\n",
    "print(rr_final.intercept_)\n",
    "rr_final.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a54e34d",
   "metadata": {},
   "source": [
    "## Compare the predicted target values with actual value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6c2f56b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABAg0lEQVR4nO3deXxU1f34/9c7y2SFLCSEJWxFRJBNJKJFpUgFrQtitdbWCq241KVabT+1tt/Wfj5d/PTXj2sXxaVixa22EbRI3UAqKgYUFYgYlC0mhIRsTPbl/P64d8JsSSbJTCaTeT8fjzySuXPn3jM38M6Zc973fcQYg1JKqegRE+4GKKWU6l8a+JVSKspo4FdKqSijgV8ppaKMBn6llIoyGviVUirKaOBX/U5E7hSRJ4N0rG+LyCvBOFYkEZHHReTX9s9niMjucLfJm4jcISKPhLsdypcG/igkIhtFpEpEEgLcf7mIvBXqdtnn+oqItIuIU0SOishuEfluZ/sbY1YbYxb1R9t6SkT2iUiD/V7KROSvIpIa7PMYY/5jjJkcQHv69Hu0X99mv59aEdkuIud30a7fGmNW9PZ8KnQ08EcZERkPnAEY4MLwtqZTJcaYVGAo8BPgYRGZ6r2TiMT1e8t67gL7vcwG8oCfe+8QIe/D5R37/aQDjwLPiUim904R9p6ijgb+6HMl8C7wOLDM/QkRGSMi/xSRchE5IiJ/FJEpwIPAaXZPr9red6OIrHB7rUdvUkTuE5GDds9wm4ic0dOGGssLQBUw1T7HZhG5R0QqgTv9nPdEEXlVRCrtXvYd9vYYEbldRD6z35vfgGXvW+jekxWROBGpEJHZIpIoIk/ax6gWkQIRyQngvXwBvAxMs49pROQGESkCiuxt59u96GoReVtEZri14SQRed/+FPQskOj23FdEpNjtcU9+jwki8gcROWBfrwdFJCmA99MOPAYkAV+yh++et69NLbDce0hPRE6331e1/W9jeV/aoHpPA3/0uRJYbX8tdgUtEYkFXgL2A+OB0cAzxphC4Drsnp4xJj3A8xQAs4BM4Cng7yKS2OUrvNjBeilW7/Jje/Nc4HNgOPAbr/2HAK8B64FRwHHA6/bTPwAuAubbz1UBf+rk1E8Dl7s9XgxUGGPex/pjmQaMAYZhXZuGAN7LGOBrwAdumy+y389UEZmNFUivtY/7ELDWDooO4AXgb1jX8+/A1zs5T09/j/8LHI/1uzrO3v8XAbyfOGAF4MT+wwUsAZ7H+n2t9tp/LNYfvgeAbPt82/vSBtUHxhj9ipIv4HSgBciyH38C/ND++TSgHIjz87rlwFte2zYCK7rax2v/KmCm/fOdwJOd7PcVoB2oBiqxgsM33c5xoLO2YQXrDzo5biGw0O3xSPta+Hu/xwFHgWT78WrgF/bP3wPeBmYEcL33YQXGaqxA/GcgyX7OAGe57fsX4H+8Xr8b6w/VmUAJIG7PvQ382u2aFff09wgIUAdMdNt2GrC3k/ezHGi1308F1ifHr7r9Tjd57d/xewZ+CuT7OWaP2qBfwfnScbjosgx4xRhTYT9+yt52D1YPdr8xpjUYJxKR27B6hKOwgtxQICvAl5cYY3I7ee5gF68bA3zWyXPjgHwRaXfb1gbkAF+472iM2SMihcAFIvIi1lzISfbTf7PP84yIpANPAj8zxrR0ct6LjDGvBfBexgHLROQmt20Ojl2/L4wdFW37OzlmT36P2UAysE1EXNsEiO3iNe8aY07v5Lne/G560wbVRxr4o4Q9ZvoNIFZEDtmbE4B0EZmJ9Z92rIjE+Qka/kq41mH9h3UZ4XauM7AmZRcCO40x7SJShfUfuq+6Kid7EM8hGu/nvmeM2RzgeVzDPTHALmPMHgA7wP8K+JU9Ub4Oq2f+aIDHdef+Xg4CvzHG/MZ7JxGZD4wWEXEL/mPxH0h78nuswBqmOtFYcxB91d3v5hQ/24PdBhUAHeOPHhdh9XCnYo2lzgKmAP/BGvd/DygF7hKRFHsSc5792jIg1x5rdtkOXCwiySJyHHCV23NDsIYEyoE4EfkFVo8/1F4CRojILfbY+BARmWs/9yDwGxEZByAi2SKypItjPQMsAr6P9ckI+3ULRGS6PZZeizVc1BaEtj8MXCcic8WSIiLn2fMW72Bdzx/YE80X4z+IQg9+j8aaoH0YuEdEhtvvb7SILA7C+/G2GviqiHzDfg/DRGRWP7dB2TTwR49lwF+NMQeMMYdcX8AfgW9j9cYvwBrfPgAUA5fZr30D2AkcEhHXMNE9QDNWMFmF52Tev7Em8j7FGpJopOthgKAwxhwFzsZ6H4ewJh0X2E/fB6wFXhGRo1jj03P9Hcc+VilWwP0y8KzbUyOwJjBrseYN3sQa7ulr27cCV2P9PqqAPVhj6hhjmoGL7cdVWL+Xf3ZynDZ69nv8iX2ud+1snNeAbu8J6CljzAGsye3bODZ3M7M/26COEc9hQ6WUUoOd9viVUirKaOBXSqkoo4FfKaWijAZ+pZSKMhGRx5+VlWXGjx8f7mYopVRE2bZtW4UxJtt7e0QE/vHjx7N169ZwN0MppSKKiPi9w1uHepRSKspo4FdKqSijgV8ppaJMRIzx+9PS0kJxcTGNjY3hborqgcTERHJzc4mPjw93U5SKWhEb+IuLixkyZAjjx4/HrZyrGsCMMRw5coTi4mImTJgQ7uYoFbVCOtQj1mLTH9vLyW21t2WKtTRekf09ozfHbmxsZNiwYRr0I4iIMGzYMP2UplSY9ccY/wJjzCxjzBz78e3A68aYSVjL4t3e2wNr0I88+jtTKvzCMbm7BKuML/b3i8LQBqWUGtDuuQdEoLY2+McOdeA3WPXPt4nINfa2HLvWuavm+XB/LxSRa0Rkq4hsLS8vD3Ezey8/Px8R4ZNPPul233vvvZf6+vpen+vxxx/nxhtv9Ls9OzubWbNmMXXqVB5++GG/r1+7di133XVXr8+vlAo9Y6yAf+ut1uM1a4J/jlAH/nnGmNnAucANInJmoC80xqw0xswxxszJzva543jAePrppzn99NN55plnut23r4G/K5dddhnbt29n48aN3HHHHZSVlXk839rayoUXXsjtt/d6ZE0pFWLXXgsxXlH5O98J/nlCGviNMSX298NAPtZycWUiMhLA/n44lG0IJafTyebNm3n00Uc9An9bWxs/+tGPmD59OjNmzOCBBx7g/vvvp6SkhAULFrBggbUoVGpqasdrnn/+eZYvXw7Aiy++yNy5cznppJP46le/6hPEuzJ8+HAmTpzI/v37Wb58ObfeeisLFizgJz/5iccnhrKyMpYuXcrMmTOZOXMmb7/9NgBPPvkkp5xyCrNmzeLaa6+lrS0YqwoqpbrS0mL18leuPLbt8GGr9x8KIUvnFJEUIMYYc9T+eRHw31jL3y0D7rK/9/mDzC23wPbtfT2Kp1mz4N57u97nhRde4JxzzuH4448nMzOT999/n9mzZ7Ny5Ur27t3LBx98QFxcHJWVlWRmZnL33XezYcMGsrKyujzu6aefzrvvvouI8Mgjj/D73/+e//u//wuo3Z9//jmff/45xx13HACffvopr732GrGxsTz++OMd+/3gBz9g/vz55Ofn09bWhtPppLCwkGeffZbNmzcTHx/P9ddfz+rVq7nyyisDOrdSqudOPRW2bDn2ePJk+OQTKK4pJr+wgPK6crJTsskblUduWm5QzhnKPP4cIN/O4ogDnjLGrBeRAuA5EbkKa03QS0PYhpB6+umnueWWWwD45je/ydNPP83s2bN57bXXuO6664iLsy5vZmZmj45bXFzMZZddRmlpKc3NzQHlvD/77LO89dZbJCQk8NBDD3Wc89JLLyU2NtZn/zfeeIMnnngCgNjYWNLS0vjb3/7Gtm3byMvLA6ChoYHhw/1OwSil+qimBtLTPbc1NEBiohX01+xeQ3piOjmpOTibnazZvYYlk5cEJfiHLPAbYz7n2GLK7tuPAAuDea7ueuahcOTIEd544w127NiBiNDW1oaI8Pvf/x5jTEBpi+77uOe233TTTdx6661ceOGFbNy4kTvvvLPbY1122WX88Y9/9NmekpIS2BvCusFq2bJl/O53vwv4NUqpnouJ8RzGuewycJ8mLCgpID0xnaEJQwE6vheUFAQl8Gutnl56/vnnufLKK9m/fz/79u3j4MGDTJgwgbfeeotFixbx4IMP0traCkBlZSUAQ4YM4ejRox3HyMnJobCwkPb2dvLz8zu219TUMHr0aABWrVpFKCxcuJC//OUvgDUnUVtby8KFC3n++ec5fPhwR7v37/db1VUp1Qs7d1pj+e5Bv73dM+gDlNeVk+pI9diW6kilvC44GY4a+Hvp6aefZunSpR7bvv71r/PUU0+xYsUKxo4dy4wZM5g5cyZPPfUUANdccw3nnntux+TuXXfdxfnnn89ZZ53FyJEjO45z5513cumll3LGGWd0Ox/QW/fddx8bNmxg+vTpnHzyyezcuZOpU6fy61//mkWLFjFjxgzOPvtsSktLQ3J+paKNCEybduzxr351LHXTW3ZKNs5mp8c2Z7OT7JTgZDiKCdW0cRDNmTPHeC/EUlhYyJQpU8LUItUX+rtT0WTdOjjvPM9t3YVd9zH+VEcqzmYn1Y3VPR7jF5FtblUTOmiPXymlQkTEM+jfdVdgKZq5abksmbyE5PhkypxlJMcnB21iFyK4OqdSSg1Ud98Nt93mua2ngyu5ablBC/TeNPArpVQQeY/Zv/ACLFkSlqZ0Sod6lFIqCJYt8w36xgy8oA/a41dKqT4xxre+zvbtMNPnLqaBQwO/Ukr10uTJ8OmnntsiIFFSh3r6IjY2llmzZjFt2jQuvfTSPlXeXL58Oc8//zwAK1asYNeuXZ3uu3Hjxo6iaj0xfvx4Kioq/G6fPn06M2fOZNGiRRw6dMjv67/2ta9RXV3d4/MqNdg0NFjDOu5B/9ChyAj6oIG/T5KSkti+fTs7duzA4XDw4IMPejzf28qWjzzyCFOnTu30+d4G/q5s2LCBDz/8kDlz5vDb3/7W4zljDO3t7axbt4507+IiSkUZEUhO9txmDOTkBPc8VpG2fFZuXUl+YT7FNcVBO3bUBP5QXkSAM844gz179rBx40YWLFjAt771LaZPn05bWxs//vGPycvLY8aMGTz00EOAFUxvvPFGpk6dynnnnddRJgHgK1/5Cq4b1tavX8/s2bOZOXMmCxcuZN++fTz44IPcc889zJo1i//85z+Ul5fz9a9/nby8PPLy8ti8eTNg1RNatGgRJ510Etdeey2B3Kx35plnsmfPHvbt28eUKVO4/vrrmT17NgcPHvT4xPDEE0903Jn8HbtgeGftUGowOHTId/K2oaFnvfxA45DrBq76lnpyUnOob6lnze41QYtbUTHGH+pKd62trbz88succ845ALz33nvs2LGDCRMmsHLlStLS0igoKKCpqYl58+axaNEiPvjgA3bv3s3HH39MWVkZU6dO5Xvf+57HccvLy7n66qvZtGkTEyZM6CjvfN1115GamsqPfvQjAL71rW/xwx/+kNNPP50DBw6wePFiCgsL+dWvfsXpp5/OL37xC/71r3+x0r3Ydydeeuklpk+fDsDu3bv561//yp///GePfXbu3MlvfvMbNm/eTFZWVkctoptvvtlvO5SKdN4Bf+pUq+5OT/QkDoW6SFtUBP5QXcSGhgZmzZoFWD3+q666irfffptTTjmlo5TyK6+8wkcffdQxfl9TU0NRURGbNm3i8ssvJzY2llGjRnHWWWf5HP/dd9/lzDPP7DhWZ+WdX3vtNY85gdraWo4ePcqmTZv45z//CcB5551HRkZGp+9lwYIFxMbGMmPGDH79619TXV3NuHHjOPXUU332feONN7jkkks66gi52tVZO4YMGdLpeZUayLZvh5NO8tzW3u6/vk53ehKHyuvKyUn1HDtKdaRS5gx8UaauREXgD9VFdI3xe3MvhWyM4YEHHmDx4sUe+6xbt67b0s2Blndub2/nnXfeISkpyee5QF4P+CwQU11d3WlJ587a1VU7lIo03v/EV6yATpazDkhP4pCrSJvrjwMEt0hbVIzxh7rSXVcWL17MX/7yF1paWgBrRay6ujrOPPNMnnnmGdra2igtLWXDhg0+rz3ttNN488032bt3L9B5eedFixZ51OJ3/TE688wzWb16NQAvv/wyVVVVQXlPCxcu5LnnnuPIkSMe7eqsHUpFkvx8/zdi9SXoQ8/iUN6oPKobq6ltqqXdtFPbVEt1YzV5o/L61ghbVAT+UF/ErqxYsYKpU6cye/Zspk2bxrXXXktraytLly5l0qRJTJ8+ne9///vMnz/f57XZ2dmsXLmSiy++mJkzZ3LZZZcBcMEFF5Cfn98xuXv//fezdetWZsyYwdSpUzuyi375y1+yadMmZs+ezSuvvMLYsWOD8p5OPPFEfvaznzF//nxmzpzJrbfeCtBpO5SKFCJw8cXHHt9/f/BSNHsSh0JdpC1qyjIX1xRTUBKa9StVz2hZZjXQ/O53cMcdnttCERr7Ow51VpY5Ksb4IbSV7pRSkct7WGf9evCakguagRKHomKoRymlvF16qf+x/FAF/YEkonv8gWa9qIEjEoYW1eDW3g6xsZ7bCgvhhBPC055wiNgef2JiIkeOHNFAEkGMMRw5coTExMRwN0VFqVGjfIO+MdEV9CGCe/y5ubkUFxdTXh6cVedV/0hMTCQ3N/xjnH2lyQKRpbYW0tI8t1VUwLBh4WlPuEVs4I+Pj++4o1Wp/hTqEiAquPyNBkf7QEHEDvUoFS7ut97HSAxDE4aSnphOQUlBuJum3Hz2mW/Qb2zUoA8R3ONXKlxCXUdF9Z13wHc44LPDxaz7XIfnQHv8SvVYOEuAqK699ppv0G9vt4J+KMscRxoN/Er1UDhLgKjOicDZZx97fO651rCOiA7PedPAr1QPhbqOiuqZ++7zfyPWunXHHpfXlZPqSPXYJ9WRSnlddGYF6hi/Ur0wUG69j3beAf+//xv+3//z3S/UZY4jjfb4lVIR54or/Pfy/QV90OE5bxr4lVIRRQTsZSYAeOGF7lM0dXjOkw71KKUiwujRUFLiua0nOfk6PHeM9viVUgNaa6vVy3cP+h9/rDdi9YX2+JVSA5aWWwiNkPf4RSRWRD4QkZfsx5ki8qqIFNnfM0LdBqVUZKmq8g36FRUa9IOlP4Z6bgYK3R7fDrxujJkEvG4/VkopwAr4mZme24yJ3kqaoRDSwC8iucB5wCNum5cAq+yfVwEXhbINSqnIsGuXby+/uVl7+aEQ6jH+e4H/Aoa4bcsxxpQCGGNKRWS4vxeKyDXANQBjx44NcTOVUuHkHfCzskCX2gidkPX4ReR84LAxZltvXm+MWWmMmWOMmZOdHZ131yk12L34ov8bsTToh1Yoe/zzgAtF5GtAIjBURJ4EykRkpN3bHwkcDmEblFIDlHfAv/RSeO658LQl2oSsx2+M+akxJtcYMx74JvCGMeYKYC2wzN5tGbAmVG1QSg08v/2t/16+Bv3+E448/ruA50TkKuAAcGkY2qCUCgPvgP+HP8Btt4WnLdGsXwK/MWYjsNH++QiwsD/Oq5QaGC680BrPd6fZOuGjd+4qpULKu5e/fj0sXhyetiiLBn6lVEgMGQJOzxUqtZc/QGiRNqVUUDU3W71896C/e7cG/YFEe/xKqaDRomqRQXv8Sqk+O3zYN+hXV2vQH6i0x6+U6hPt5Uce7fErpXpl+3bfoN/aqkE/EmiPXynVY94Bf+JE2LMnPG1RPac9fqVUwP7+d//lFjToRxYN/EqpgIjAN75x7PF3v6vDOpFKA79Sqks/+5n/Xv5jj4WnParvdIxfKdUp74D/pz/B9deHpy0qeDTwK6V8LFgAGzd6btNhncEj4KEeEUkJZUOUUuF3sLoYEc+gv2GDBv3BptvALyJfFpFdQKH9eKaI/DnkLVNK9SsRGJuR67Htj1v+xHEnFYepRSpUAunx3wMsBo4AGGM+BM4MZaOUUv2nrs53LP++NRtZ+8mLpCemU1BSEJ6GqZAJaIzfGHNQPP9ltIWmOUqp/uSv3MLaT46tmJLqSKXMWdaPLVL9IZDAf1BEvgwYEXEAP8Ae9lFKRaZdu+DEEz23PfHOS8Qk1wBDO7Y5m51kp2T3b+NUyAUy1HMdcAMwGigGZtmPlVIRSMQ36BsDC6bMorqxmtqmWtpNO7VNtVQ3VpM3Ki88DVUh022P3xhTAXy7H9qilOqB4ppiCkoKKK8rJzslm7xReeSm5Xa6/7PPwje/6bmttRViY62fc9NyWTJ5CQUlBZQ5y8hOyWb+uPldHlNFpm4Dv4isAm42xlTbjzOA/zPGfC/EbVNKdaK4ppg1u9eQnphOTmoOzmYna3avYcnkJX4DdaClk3PTcjXQR4FAhnpmuII+gDGmCjgpZC1SSnWroKSA9MR0hiYMJUZiGJow1G8GzvXX+y+3oHn50S2Qyd0YEcmwAz4ikhng65RSIVJeV05Oao7HNu8MHO+An51trZSlVCAB/P+At0XkefvxpcBvQtckpVR3slOycTY7GZrgm4GTmwtffOG5v/bwlbtAJnefEJGtwFmAABcbY3aFvGVKRaieTrr2Rt6oPNbsXgNYPX1ns5PqxmqumOmZh7FiBTz8cFBPrQYBMZ10BURkqDGm1h7a8WGMqQxpy9zMmTPHbN26tb9Op1SvuU+6ugfkziZd+3ou1x+Ya/Ou8Xlee/lKRLYZY+Z4b++qx/8UcD6wDXD/JyT24y8FtYVKDQLuk65Ax/eCkoKgB/7ctFxGDcntSMd0efJJ+LYmYKsudBr4jTHni1WnYb4x5kA/tkmpiBXIpGuwBJqiqZS3Lsf4jTFGRPKBk/upPUpFtK4mXYOlosLK0HG3Y4fv3bjd6Y+5CDUwBZLH/66I6D3bSnWjuKaYivoK/vXpv3h97+scrjsc9LIHIr5B35jeBf01u9dQ31JPTmoO9S31rNm9huIaLcEcDQIJ/Auwgv9nIvKRiHwsIh+FumFKRRJXIE2OT2bhhIUAvPb5azS0NPR5Yre4ppj/fWajz9BOVVXvh3Y6uwHs5T0vk1+Yz8qtK8kvzNc/BINUIHn854a8FUpFOPdAOjRhKAtTF1LbVEtyfHKfg/6Y9FzA8xgHq4tJ78Nx/c1FNLY0smHvBs47/ryAykCoyNVpj19EhovIvcCfsCp0Vhlj9ru++quBSkWC8rpyUh2pHttSHamU15X3+pj33Ycd9I9ZU/giT364us+Lo7jmItx9XP4xw1OHd1sGQkW+roZ6ngDqgAeAVOD+fmmRUhHIXyDty6SuCNxyi+e2tZ+8iEjf/6CAdQOYdwnmMmcZ04dP99gvGOdSA09XgX+EMeZnxph/G2NuAmb0V6OUijT+AmlvJnVnz/ZN03zyw9Ueq2IFI0vIVYI5OT6ZMmdZx9xEYlyix366EMvg1NUYv9glmF3/DGPdH3d3566IJAKbgAT7PM8bY35p3wn8LDAe2Ad8w1UATqlIFYxa9t4BPya2nYe2PMbeqkNMyJjgcSfw/HHzg9Jm9/a5JqiBoJ9LDSxdlWzYB7RzLPC7M8aYLu/ctW/+SjHGOEUkHngLuBm4GKg0xtwlIrcDGcaYn3R1LC3ZoAYzfzdiPfnh6o7gu69qH8NTh2OMCXm+veb2DxzB+F30uGSDMWZ8z5vq8XoDuAY94+0vAywBvmJvXwVsBLoM/EoNVt5B/9Szv+DGP2z0KPkwPmM8yfHJLJ2yNOTt0YVYBoaeLrTTU4Hk8feaiMSKyHbgMPCqMWYLkGOMKQWwvw/v5LXXiMhWEdlaXq6TS2pwEfG/QMp3f/uvoGcHqcgT6EI7vRXSwG+MaTPGzMJKQj5FRKb14LUrjTFzjDFzsr1vVVQqAMU1xQPuZqSWFt+A/+ijx27ECnZ2kIpMoUgPdhfSwO9iL924ETgHKBORkQD2d10TSAVVcU0xj2x7hB+/+mPe3P8msRI7IEoSiIDD4bnNGPie2+rVwcoOUpEt1B2Arm7gyuzqq7sDi0i2iKTbPycBXwU+AdYCy+zdlgFr+vwulLK5xkZ3lO9gZOpIYiWWgpICmlubw3YzUlGRby9/27bOFzv3TrPUO2ejT6g7AF2lc7rq8AswFqiyf04HDgATujn2SGCViMRi/YF5zhjzkoi8AzwnIlfZx7m0T+9AKTeusdGWthbSE9OJEatvU1RZxNzcuSEpj9yV3pRO1glWFYz04K50ldUzAUBEHgTWGmPW2Y/Pxeq9d8kY8xFwkp/tR4CFvW2wUl1x1aBJS0yjsbWR5PhkkuKSqGqs6tex8lWrYPlyz23fffqHnDZpKsU152pgV90KZQcgkDH+PFfQBzDGvAzoHR1qQHKNjU7KnERdcx31LfXUtdQRHxvfb2PlIr5B/4cv30paOmw+uJnHtz8+ICaaVfQKJPBXiMjPRWS8iIwTkZ8BR0LdMKV6wzU26oh1kDc6jzbTRpmzjBOzTwz5WPkZZ/gO7fxg3S3cuv42UhwppDpSGZY0jIqGCi18psIqkLLMlwO/BPKxxvw32duUGnDcx0brmuuYP25+v9x96m8s/6GClWw/1EyqI6NjW1JcEpUNlZqXr8Kq28Bv1+S5WURSjTHO7vZXKtyCOTba3W3zXU3e5hdm44hzdMw1ADS0NuCIc2hevgqrbod6ROTLIrIL2GU/nikifw55y5QKs+6WJ+wuYydvVB7ZSdlU1FdQ11yHs9nJkYYjZCVlaV6+CqtAhnruARZj5d9jjPlQRM4MaatUVBmohcHcb5sHOr57L44CnefkL5u1jPV71rO1dCtihHlj5nHucZrVo8IrkMCPMeageHZv2kLTHBVtQl2Mqi/8LU94xcxvezweNgwqKjo/Rm5aLitOXsEKVoSiiUr1SiCB/6CIfBkwIuIAfgAUhrZZKlp01qsuKCnoVeAP5qcHV2ro0IShXHjCBT7P93ahc6XCLZB0zuuAG4DRQDEwC7g+hG1SUSSYxai6G5PvqbxReZRV1vkE/Zt/XKtBX0W0QHr8k40xHp9vRWQesDk0TVLRxL1X7dLbO2yD/enBGsu/xmPbwerisA9BKdVXgQT+B4DZAWxTqsfyRuX1ebk/1/DOP3b9g9y0XCZnTgas+jzVjdUYYzyGfLobDnrvPZg71/Mc777r2qZBX0W+TgO/iJwGfBnIFpFb3Z4aCsSGumEqOvSmGJV74BYRDjsPMz5jPGPSxlDTWMMbe9/AGEPOkBwS4xJpp71jwhhg1fZVlDeU09zajCPOwa7Du1g2axm5abm9KqqmVKTpqsfvAFLtfYa4ba8FLgllo1R06ckNV95ZQBv2baCqoYpRQ0dx/LDj2VK8hcMNh3HEOEhuSmZ/zX5GpI6gqLKI9XvWA/Bp5adkJWcRGxPL51Wf817xe+Q/NJNtT3u24ehRSE311wqlIltX1TnfBN4UkceNMfv7sU1Kdcp7HL+lrYVhScMoqizitNzTmJs7l0/KP2Hv0b18VvUZuUNyreXriOH1va8TJ3Fkp2TT2t5K0ZEiEuMTeefqt33Oo718NZgFktXziGtBFQARyRCRf4euSUp1zjsLKC0hDYOhprGmY5vECMkJyUzKnESyI5miI0U4m53kpOZwuP4wBkPJ0RI23vQ0ay5/weP4/9yVr0FfDXqBBP4se+lEAIwxVXSyQLpSoea9JN2kzElUNVYRHxtPu2nnw7IPyUrOwhHjAAOOGAciwv6a/UzPnk5KXArbD23n+cv+TlNNhsexXyhco8XTVFQIJKunXUTGGmMOAIjIOKwqnUr1O+8sIEecg+MyjmNE6gjKnGU0tTRxzsRz+KD0Aw4cPUBdSx0p8SkkxydT11JH/rf+6XPMpU9dzAWTL8DZrMXTVHQIJPD/DHhLRN60H5+Jd3KzUv3EXxbQ8lnLOyaH8wvzqW+p5+RRJ9P6RSspjhSMMbTTzs2n/cDneIufOIcRQ76EI87R4zRSpSJVIGWZ14vIbOBUrDV3f2iM6aI6iVKh1VUWkOsTQXpiOnmj8nj74Ns8tvRRn/1++todfFH7BUebkil1lpIcnxzUNU2VGsi6yuM/wRjziR30AUrs72PtoZ/3Q988NRgEu/pmV8dz/0RwoPqgT9BPzirn4gdvpal1OLlDc6lqqKK1vXXAVARVqj+I6SSFQUQeNsZcLSIb/DxtjDFnhbZpx8yZM8ds3bq1v06ngsg97979ztzeVt8M9Hj+bsR6bNtfeeKjJ3DEOcgbmUdDawN1zXVMzZ7KmLQxLJ2ytC9vVakBR0S2GWPmeG/vKo//avv7glA2TA1uvamf01WPvrvjlZbCqFGexzv/is+55uc7gSxyh+RSXl9OVWMVaQlpTBs9jczkTMqcZSF490oNTF0N9Vzc1QuNMb7pEUp58VfTPtWR2mmg7a4+f1fH89fLf/LD1R4F4IalDGNYyjAWTljYsa22qbbfs3kG6uIzKjp0lcd/gf11FfAo8G376xHgitA3TQ0G3nn30HX1TfcefYzEMDRhKOmJ6RSUFHR6vJeeyeHaPM9EszfesCppVjdWU9tUS7tpp7aplqykLLKTsj22VTdW9+tSiMEuH61UT3U11PNdABF5CZhqjCm1H48E/tQ/zVORrqfVN7v7hOB9vIumLPE5xrFpK/+pn0CPisIFW7DLRyvVU4Hk8Y93BX1bGXB8iNqjBplAqm+6D3t8VvUZja2NTMiY0PG8+ycE1/HmTE+n7KBnBTWnE1JSfM/vL5iGM8D2dPhLqWALJPBvtGvzPI11x+43AX+ZPkr55R58XUF+XdE6slOyyR2Sy3sl73WM6Te2NrL5oLXGz7j0cX4/IXS22HlxTTGvFA78cfNgLj6jVG90ms7psZPIUqw7dgE2GWPyQ9oqL5rO2XcDYTLRXyrmm/veZNrwaR09/Ir6Ct468BZf1HzB+MzxzBk5h3OOO6fTWvkrtz7M+yXv42x20mbaODX3VI8/GANh0XZvwU5xVaoznaVzBlKkDeB94F/GmB8C/xaRId29QA0cA2Uy0d/EbZtpo9RpjSRW1FewpXgLaQlpfCnzS5wx9gya2poA/3n5/7Px12w+uJnE+ESqm6o5UHuAgi8KqKyv9JkUHkhcw1XJ8cmUOctIjk/WoK/6VbdDPSJyNVZtnkxgItai6w8CC7t6nRo4Bspkor+x7eyU7I6x7aLKIlIc1iC9q71XzPw2N3odxxirJs+b+ysYljSM5Phk2k07w5KGUdNUQ1FlEVkpWQN63Lwni88oFWyBjPHfAJwCbAEwxhSJiJZljiDhnkx0DTO9f+h9EuMSmTl8JogV6D+v/Jyqxir2Vu2luqGahLgEGloamDZ6GheecIHPsVwjk+V11tKJmUmZACTHJ9Pc1kxreys1TVZtfh03V8q/QAJ/kzGmWezP2iISh5ZljijhnEx0H8/OG5XHpv2bWLdnHQ5xkJaURnxMPJmJmTy36zliJZbjMo7jsaWP8pDXcbynorJTsnHEOWhobSA5PplRqaPYUb6DuNg4hiQM6cjP12qbSvkKJPC/KSJ3AEkicjZwPfBiaJulgqmnufTBtH7Peooqi2hpayEtMY1xQ8fxr6J/4Wxx8qX0L5EUl8SEzAmMHjqa6oZaHlv6iM8xDlYXA57DInmj8th5eCd7qvbQbtqJjYklIzEDR5yD9IR0rbapVBe6zeoRq6u/AliEVZb538AjJpB0oCDRrJ6+62lWj2v/3RW7qWqsIjMxk+Ozju9RNlBxTTE/fvXHjEwdSVJ8EuV15Ww/tJ3axlpiY2NJjksmIS6B2SNn88B59/u8/r9e+QmXTLmEvFz/d9UW1xTz8p6Xeb/kfYwYjwwgpVQvirTZL4oBPjLGTAMeDlXjVOj1ZDLRNTzT1t7G3uq9xEos1Q3VJMUnUXK0JOAMlIKSAnJScxARYiSGL5xf4Gxx0tzeTFZiFs3tzVR+OpEHVngG/TF523ngif04m2fwXsl7jBwystObsK4++Wo4ObBroJSydBn4jTHtIvKh+9KLgRKRMcATwAigHVhpjLlPRDKBZ4HxwD7gG/Y6vmqAcGUB7Ty8k1RHKsnxydS31HOo7hAnZp8YcDZQeV0507Ond6RUltaWkhCbQGtbK0lxSRRc9Z7Pa77/4vWkJ6YTI6dpKQOlQiSQMf6RwE4ReQ+oc200xlzYzetagduMMe/bef/bRORVYDnwujHmLhG5Hbgd+EmvWq9CwpUFVNNUQ0aitSB5Ylwi1Y3VPcoGyk7Jpr6lnrmj51JUWURTWxPxsfEcffIxigpO99j3lgfWU5P7HG0mnkmZkzq2e5/P35AVEPab05SKJIEE/l/15sB2fZ9S++ejIlKIdQ/AEuAr9m6rgI1o4B9QXFlAaQlpHVkzja2NpCWm+WQDdTV3kDcqj8e3P05FQwXNrc2MSB3BG8tf9znfdWu/T076OPYVV+GIc1BUWQRAVkqWx/n8lWx+fPvjCML4jPF+yzh310alolFXK3AlAtcBxwEfA48aY1p7dRKR8cAmYBpwwBiT7vZclTEmw89rrsFe1H3s2LEn79+/vzenVr3gPsa/s3wnsRJLW3sbJw4/kdiY2I6g6q/0wL6qfQxPHY4xBhFhz5E9NLU3cd+59/qc54Y1tzEiLYPFExfzXsl71vkO7yQ2JpaaphoS4xJpaGlgwYQFnHvcuRSUFFDfUu+Rlvr6XusPiXd9/eT4ZJZOWarlEVRU683k7iqgBfgPcC4wFbi5FydOBf4B3GKMqRV/9977YYxZCawEK6unp+dVvedeUbO+pb4jq2dM2pguV8Nqbmvm08pPKW8oZ8H4BWzYt4GqhiqeuHiVzzkeKlhJdsrp5I3K8zjOkIQhvF/6Pp9Xfc6w5GEsnbyUxPhE1uxeg7PJyQnZJ3gcp7m12efY7sNDA+WuZaUGkq4C/1RjzHQAEXkU8J2J64aIxGMF/dVuK3aVichIY0ypXdv/cE+Pq0IvkCwg7zuCiyqLGJY0jKa2JmIkxm8v/4XCNZQ5y7hmzrGFU9YVres4TlZyFkMShnBa7mk0tTUxPPXYTeIHag743IjmiHP4nMN9eCjcdy0rNRB1FfhbXD8YY1oD7am72Pn/jwKFxpi73Z5aCywD7rK/r+nRgZVf4RjH9r4juKaxBkesg7SENL/lFtZ+8iK1Tb53DHd1HJdURyoZiRlUN1Z3PHY2O8lKykIQaptq/d6cpiWQlfLVVXXOmSJSa38dBWa4fhaR2gCOPQ/4DnCWiGy3v76GFfDPFpEi4Gz7seqDcFXfzBuV57G0YXxsPPeeew+/O/u3Hvvd/PItvFC4hr1Ve3lz/5vsrthNfmF+R/v8Haeqscoju8fZ7GRy1mSfqpbLZy1n2axlnVa69D52OJZaVGqgCagef7jpnbtdyy/M75j0rKivoKiyiENHD5Gdks1Np9zU555/V58m3J/zXvcW4Efrf8zkrMkcqT/CZ1WfMW34NL/18t2PEyMxHHIeYkLGhKBMyGpWj4pWnU3uauAfBFZuXUlOag6VDZVsKd5CiiOFhNgEyurKmD1ydp8yWALJivE3Cvj9F6/HEecgOymbZbOW+c3Icc++8XdeDdZK9U2vSjaoyOAax3bVs3fdaZuTktOxGElvg2ZXWTHDk3JJSPB9zQ3/uhFjhOT4ZIYkDOkI4D2ZZNV69UqFjgb+QcBVffPQ0UOMSB1BfUs9dc11TBs9rSO49rYH3VnAvmjKEp99v/OPKzlYe5DC8himZk+lqbWJnYd30tDSwPFZx+skq1IDRKBLL6oBzJV3n52STVldGQmxCcwdPbfjzlcR6fXkr+vTREV9Be8Uv8NfX9ztE/TP/+5O1n7yInUtdSTGJTIkYQiHnIdIjk8mNiaWysZKnWRVagDRHv8gkZuWy02n3OQxHu8KrgmxCb2+iSlvVB6rtq/i08pPO70Ry/pEEENKfArOZiem3VDXWkd9Sz1tpq2j3o8j1sFb+9/qKKGsZRWUCg8N/IOI+x23Zc4yslOymT9uPuuK1pHqSKWizsr4qWmqYUjCENIT0gM65ht/WcIbz07z2H7Fg78jddQBPqsaSmNrIxMyJpCblktiXCKH6g5hMCTEJjAuexxJ8Ukdf5DOmXROxwSxi78aPN71dpRSwaOBPwJ11Tv2NymanZLN/ur97CrfRYojhYzEDCobKqlsqKS4prjL4Gpl7HgG/WvXXmcXbhNGDxnN5oObAZiYMZEvar8gMymTM8acQWJ8Inur9vJJxSc0tjYyYsgIJmVOIis5Czj2iaOzCeT1e9YzLHmYfgpQKsh0jD/C9OZmrbxReew4vIMYibEKn7U20G7amZY9raNWvjcR3zTNF3a9yE9fu4MURwoiQnpiOhMyJjA1ayob9m5gw94NpMSnMCVrCm2mjfqWegShqa2JEakjaGptYkvxFirqK0h1pFJeVw5YE8ipjlSPczW2NvL63tf7/aY0paKBBv4I4947jpEYhiYM7UjZ7ExuWi4TMyaSlphmjfnHJTA3dy7j0sd1BF93/vLy/7jlTzhbaqluqKbdtFPXXMekzElU1FXwaeWn1DbVMjRhKI44B61trXxt0tfISs6yyiWn5NDU1kRyfDIpjhSKKos8MnpcE8juPj78MTmpOT16n0qpwGjgjzD+esfuvefOHJ91PNOGT+Oc487htNzTyErO8kmn9NfLN8b6cpVKaKcdg+nIGtpWuo0DNQdISUghIymDWInl08pPWb9nfUdbJ2VOoq7ZmuxNiE3g0NFDHhk9/jJ+DjsPMz17eo/fp1Kqexr4I4y/3nEg+fDdpVP66+W739Sdm5bL0ilL+fkZP2dS5iQccQ7aTTuFRwqJi4ljQvoEYiSG5PhkhiUNY2vp1o62ZqVkMXf03I67ibNTsj0mbl2T0u71dhZMWEBifGKP36dSqns6uRthXDdrAT7VKLub9PWX8TMm3Xey1KqVn01xje9kqvdx4iSOMRljPG7MMhjEiEdbM5MzOTHuREY3jvabreM9Ke2ay/D3PpVSfaO1eiJQZ+vO9nSlKX+9/JtfvoXpw6d3rLHbXUrlw9seZvPBzQxLGkZSXBINrQ0caTjCvDHzuPrkq/uUn6+5/Ur1jRZpG6RcwfGVPa+QEJ/AzJyZHemSnRVB6yzgC0KMxFDXXMfc3Lk4Yh0kxyd3rJLVWXVO93V1HXEOspKyWDxxMcVHizVoKxVGnQV+HeOPYO6pnSJCDDEd6ZLgOxna0OAb9GedXsaTH66mpa2FlPgUj8ybVEcquyt2d5k+mpuWy/JZy5k/bj6zRsxi/rj5HWvoaiqmUgOTjvFHMPfUzvTEdJramjqCtnfWTmeTtyu3riHVkUNaQhoNrQ0kxyd3DPM4m51UNVYxJm1Ml+UevMfn8wvzdZ1bpQYw7fFHiOKaYvIL81m5dWXH6lXuqZ2ulMl20051Q3VH1k7KkS/73oj1wrGMHVfmjXvKZUNLA/Gx8VQ3VpOZmNnj9NHeppwqpfqHBv4I0NnduiLSkdrpSpk0GNppJzk+mRvn3sDiMzxLKhsDS9yKa7rSPB1xDvJG5dFm2ih1ljItexpLJi/pKKfsrru0yt6mnCql+ocO9UQA71o2za3NFFUWcaTuCEnxSR3LGTriHEzKnETxuiu4+II0j2NUVMCwYb7Hdk/PrGuuY/64+T4TsT1Nq+wq5VQpFX4a+COA+2IoFXUVbPliC0nxSQxJGMIJWSewo3wH9S31TM6azBUzv+3z+u4St7pa7aqz/P+uxup78xqlVP/RwB8BXEMnQxOGdiyvCJCeZBVJG5Y8jD/c8FW2v+U5rPO37aupaaqmuCa45Y1Lj5Z2m1+vSycqNXBp4A+Tntyc5D50Ut1YTWJcIvUt9UwbbpVL9tfLX/vJi8BQRPqWTeNdK39/9X6e2fEM88bMY1z6OK2dr1QE0sAfBj1deMR96MQYa/J2bu5cvjf7uz77vlC4hhg5Nmef6kilsLyQ/ML8Xt1M5T2/cMh5iGFJwzhUd4gJGRN6laqpd+QqFV4a+MOgs4VHugqerqETV+/fX9D/5658nM31HnVz9lfv5/PqzxmTNqZXq1t5L7Ze01RDemI6NY01HdtcC7oH9N6LC3j4/YdpM21kp2TT2NpIydES/cSgVD/SdM4Q8Jdz7643ee6uY45Jz+XGuTd4PHewuhhj/Ffg3HF4B9Oyp/W6rr13amZaglXTPy3xWNZQoKmaxTXFPPzBw8TFxDEydSQtbS3sKt9FW3ub1tlXqh9p4A+yQFbI6mmeu+uYF0/1rLlz+ZVOjKHL8sYTMyYyLn2cx+t6cjOV9x+TEakjONJwhBEpI/yWd+5KQUkBrW2tZCRlICId5SFKnCV6c5dS/UiHerz0dfw5kGGcnua5W6WTPXv5T364muT4ZMDzj4G/8gmujCCXntxM5Z2aOSZtDD/K/RHFR4t7nKrpGjZqbG202w5JcUmUOkuZO3puQO1RSvWdBn43PZ109cd7TBx8x8ADzXNvaoJEz7VI+J+/vsPM0ypoN4GNqwfjZip/qZl5dN/D9+Ya099VvguAxLhEqhqqiJXYgD4xKKWCQwO/m95Munpzz7l38dfD7i7P3V9RNStFs/Nj+jOQbqbKG5VHydESpmZPpdRZSunRUuJi47h69tU6satUP9LA7yaQ3np3XD3sI/VHKHWWWqtUxcZx9UlXB/T6/fth/HjPbVt2lFJQ909qm9J71WsfKDdTuf8RSoxL5JTRp2gqp1JhoIHfTaC99a7kpuVyyqhTOlIWh6cOZ1TqKN4reY+RQ0b2uJdvlVsYyaiagdFr76uB8kdIqWimgd9N3qg8Vm1fRXlDecdqUtlJ2SybtaxHxyk+Wsz88fM9/oDUNtV2OmT073/DOed4bmtqAofj2GMNmEqpYNHA78VgunwciJ4MGXXey1dKqdDQwO+moKSACRkTmDliZse2rnrqnQlkyOjuu+G22zxfpwFfKdUfNPC7CcbkLnSfQqm9fKVUOIXszl0ReUxEDovIDrdtmSLyqogU2d8zQnX+3gjWylH+7qBdMnkJv/5Jrk/Qf/LD1fxxy590IXKlVL8JZY//ceCPwBNu224HXjfG3CUit9uPfxLCNvRIMFeO8p6M9Q74Cy8+wM2//RDQhciVUv0rZD1+Y8wmoNJr8xJglf3zKuCiUJ2/NzrrqfclIJ97rm/Q/84/ruSU7z9IRV0FoAuRK6X6V3+P8ecYY0oBjDGlIjK8sx1F5BrgGoCxY8f2U/OClzZpDMR4/Vn92q/upfVLL3OwtpnEuEQqGyqZO3qulTaqC5ErpfrJgK3OaYxZaYyZY4yZk50dWUHx+ut9g/5PX72DE+Ye5ITME4iRGA7VHSIpPokPD38YcHVLpZQKhv7u8ZeJyEi7tz8SONzP5w+p1laIj/fc9rsXVzPluFRe+ayGjMQMJF6Ymj2VPUf20NTaRDvtugiJUqpf9XePfy3gug12GbCmn88fMvPmeQb9ceOs4Z7JE5NxNjtJS0ijobUBAEesg5NGncS8sfNYPHGxBn2lVL8KZTrn08A7wGQRKRaRq4C7gLNFpAg4234c0Wprrcnbt98+tq2+Hvbts352LWQyInUEzmYnR+qP4GxyMiJlhA7xKKXCImRDPcaYyzt5amGoztnfHA5oaTn2+KKLID/fcx/3ipT1LfVUNVaRmZjJmLQxWplSKRUWeuduL/grndzW5juh66IF1pRSA8mAzeoZqEQ8g/7Pf+4/dVMppQYq7fEH6L33YK7XsrBaX0cpFYm0nxoAEc+gv2qVBn2lVOTSHn8X/vEPuOQSz20a8JVSkU4Dfye86+ts3Ajze16rTSmlBhwN/F5274YTTvDcpr18pdRgomP8NmPg4os9g/7u3Rr0lVKDz6Dt8RfXFFNQUkB5XTnZKdld3ixVUACnnHLs8erV8K1v9VNDlVKqnw3KHn9xTTFrdq+hvqWenNQc6lvqWbN7jc8qV+3tVraOK+iPHAmNjRr0lVKD26AM/AUlBaQnpjM0YSgxEsPQhKGkJ6ZTUFLQsc+rr0JsrJWfD/Dyy1BSAgkJYWq0Ukr1k0E51NPVounNzTBxIhTbnf+TT4YtW6w/AkopFQ0GZY+/s0XTd2+aRULCsaD/zjuwdasGfaVUdBmUPX7vRdMrqhu5et7lmHbr79wFF8CaNb65+kopFQ0GZY/ffdH0Zx4bxorTLusI+rt2wdq1GvSVUtFrUAZ+sIL/P36zlGf+v9MBuOYaKyd/ypQwN0wppcJs0AZ+OFZY7cABeOih8LZFKaUGikEd+G+6yerljxkT7pYopdTAMagDv1JKKV8a+JVSKspo4FdKqSijgV8ppaKMBn6llIoyGviVUirKaOBXSqkoo4FfKaWijJgIWFtQRMqB/eFuRx9lARXhbsQAotfjGL0WnvR6eOrL9RhnjMn23hgRgX8wEJGtxpg54W7HQKHX4xi9Fp70engKxfXQoR6llIoyGviVUirKaODvPyvD3YABRq/HMXotPOn18BT066Fj/EopFWW0x6+UUlFGA79SSkUZDfwhICKPichhEdnhti1TRF4VkSL7e0Y429hfRGSMiGwQkUIR2SkiN9vbo/V6JIrIeyLyoX09fmVvj8rrASAisSLygYi8ZD+O5muxT0Q+FpHtIrLV3hb066GBPzQeB87x2nY78LoxZhLwuv04GrQCtxljpgCnAjeIyFSi93o0AWcZY2YCs4BzRORUovd6ANwMFLo9juZrAbDAGDPLLXc/6NdDA38IGGM2AZVem5cAq+yfVwEX9WebwsUYU2qMed/++SjWf/DRRO/1MMYYp/0w3v4yROn1EJFc4DzgEbfNUXktuhD066GBv//kGGNKwQqGwPAwt6ffich44CRgC1F8Peyhje3AYeBVY0w0X497gf8C2t22Reu1AKsT8IqIbBORa+xtQb8ecX09gFKBEJFU4B/ALcaYWhEJd5PCxhjTBswSkXQgX0SmhblJYSEi5wOHjTHbROQrYW7OQDHPGFMiIsOBV0Xkk1CcRHv8/adMREYC2N8Ph7k9/UZE4rGC/mpjzD/tzVF7PVyMMdXARqz5oGi8HvOAC0VkH/AMcJaIPEl0XgsAjDEl9vfDQD5wCiG4Hhr4+89aYJn98zJgTRjb0m/E6to/ChQaY+52eypar0e23dNHRJKArwKfEIXXwxjzU2NMrjFmPPBN4A1jzBVE4bUAEJEUERni+hlYBOwgBNdD79wNARF5GvgKVjnVMuCXwAvAc8BY4ABwqTHGewJ40BGR04H/AB9zbBz3Dqxx/mi8HjOwJuhisTpezxlj/ltEhhGF18PFHur5kTHm/Gi9FiLyJaxePljD8E8ZY34TiuuhgV8ppaKMDvUopVSU0cCvlFJRRgO/UkpFGQ38SikVZTTwK6VUlNHArwYdEVkqIkZETghg31tEJLkP51ouIn/sZHu5XWVxl4hc3cnrLxSRaCtCpsJMA78ajC4H3sK6Kag7twC9DvzdeNYYMwvrno7fikiO+5MiEmeMWWuMuStE51fKLw38alCxawLNA67CLfDbhdH+YNc6/0hEbhKRHwCjgA0issHez+n2mktE5HH75wtEZItdN/417yDeFfv2+8+AcSLyuIjcbZ/vf90/MYhIjojk27X6PxSRL9vbr7Br+G8XkYdEJLaPl0lFOQ38arC5CFhvjPkUqBSR2fb2a4AJwEnGmBlYdYPuB0qw6p8v6Oa4bwGnGmNOwqor81+BNsi+I/NLwB570/HAV40xt3ntej/wpl2rfzawU0SmAJdhFe+aBbQB3w703Er5o9U51WBzOVapX7AC9OXA+1g1cR40xrQC9OKW91zgWbtIlgPYG8BrLrNLVjQB1xpjKu2qpH+3K3R6Owu40m5fG1AjIt8BTgYK7NcmEUVFy1RoaOBXg4Zd0+QsYJqIGKx6OEZE/gsQrFrn3XHfJ9Ht5weAu40xa+26MncGcKxnjTE3+tleF8BrXQRYZYz5aQ9eo1SXdKhHDSaXAE8YY8YZY8YbY8Zg9cxPB14BrhOROLDWMbVfcxQY4naMMhGZIiIxwFK37WnAF/bPywiN14Hv2+2LFZGh9rZL7PrsrvVXx4Xo/CpKaOBXg8nlHKtu6PIP4FtYS/sdAD4SkQ/tbQArgZddk7tY65m+BLwBlLod507g7yLyH6AiJK231p5dICIfA9uAE40xu4CfY63K9BHwKjAyROdXUUKrcyqlVJTRHr9SSkUZDfxKKRVlNPArpVSU0cCvlFJRRgO/UkpFGQ38SikVZTTwK6VUlPn/AamvWjsRX39lAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(price['Price_actual'],price['Price_predicted'], color = 'green', alpha = 0.3)\n",
    "plt.plot(price['Price_actual'],price['Price_actual'], color = 'blue', alpha = 1)\n",
    "plt.legend(['Actual Price','Predicted Price'])\n",
    "\n",
    "plt.xlabel('Actual Price')\n",
    "plt.ylabel('Predicted Price')\n",
    "plt.title('Actual Price vs Predicte Price')\n",
    "plt.show()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d85a85",
   "metadata": {},
   "source": [
    "### Also Perform:\n",
    "- EDA\n",
    "- preprocessing\n",
    "\n",
    "### Further Consideration:\n",
    "- Features Selection\n",
    "- Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6450f891",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
